---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR].... Our data [@shelter].... Following @tellingstories, we consider...

Overview text

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.



Some of our data is of penguins (@fig-bills), from @palmerpenguins.

```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false

ggplot(penguins, aes(x = island, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange","purple","cyan4"),
                    guide = "none") +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

analysis_data |> 
  ggplot(aes(x = width, y = length)) +
  geom_point(alpha = 0.8) +
  theme_minimal() +
  labs(x = "Wing width (mm)",
       y = "Wing length (mm)")
```

Talk way more about it. 

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.








# Model

The goal of our modeling strategy is to estimate the support percentages for leading candidates in the 2024 U.S. presidential election, with a specific focus on Kamala Harris and Donald Trump. This approach accounts for potential variations in support across time, different pollsters, and geographic regions, ensuring a robust prediction framework that balances accuracy with interpretability. We implement both linear and Bayesian models to capture these patterns and examine the influence of polling quality and state-specific factors on the predicted support levels.

The linear model employs multiple regression, with candidate support percentage as the dependent variable and key predictors such as pollster rating, sample size, geographic region, and polling methodology. This model provides an interpretable framework, allowing us to assess the direct impact of each factor on candidate support. However, to account for more nuanced, hierarchical patterns within the data, we extend this analysis using a Bayesian framework.

The Bayesian model incorporates pollster and state-level random effects, enabling us to model variations across different polling organizations and geographic areas more effectively. By including weakly informative priors, the Bayesian model offers greater flexibility while controlling for overfitting, providing a more comprehensive view of voter support trends. Together, these models create a reliable foundation for forecasting support in the 2024 election, with each approach highlighting distinct aspects of the polling data.

## linear Model set-up

Define $y_i$ as the support percentage (pct) for a candidate in the 2024 U.S. presidential election polls. The linear model includes several predictors: $α_i$ (poll reliability score), $β_i$ (numeric grade indicating poll quality), $γ_i$ (transparency score of poll methodology), $δ_i$ (poll duration), $θ_i$ (sample size), $κ_i$ (type of population surveyed), $λ_i$ (whether the poll is hypothetical), and $μ_i$ (poll methodology type).

The model is specified as follows:

```{=tex}

\begin{align} 
y_i | \mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \times \phi_i + \beta_2 \times \beta_i + \beta_3 \times \gamma_i + \beta_4 \times \delta_i \\
      &\quad + \beta_5 \times \theta_i + \beta_6 \times \kappa_i + \beta_7 \times \lambda_i + \beta_8 \times \mu_i \\
\alpha &\sim \mbox{Normal}(0, 10) \\
\beta_j &\sim \mbox{Normal}(0, 2.5) \quad \text{for each } j = 1, \dots, 8 \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

```
We run the model in R [@citeR] using the lm() for linear regression, along with tidyverse [@tidyverse] for data manipulation and visualization.

### Model Justification

This linear model aims to estimate candidate support percentages in the 2024 U.S. presidential election by accounting for various poll characteristics and methodological factors. The model includes multiple predictors, represented by $φ_i$, $β_i$, $γ_i$, $δ_i$, $θ_i$, $κ_i$, $λ_i$, and $μ_i$, each of which captures different aspects of the polling data that may impact candidate support.

The variable $φ_i$ represents poll reliability scores, with higher values expected to correlate with more stable support estimates. Similarly, $β_i$ and $γ_i$ denote quality-related factors such as numeric grade and transparency score, which likely influence the reliability of the polls. Poll duration ($δ_i$) and sample size ($θ_i$) add further depth to the model by reflecting the scope and stability of each poll's data. The variables $κ_i$, $λ_i$, and $μ_i$ account for population type, the hypothetical nature of the poll, and poll methodology, respectively, allowing the model to adjust for methodological differences across polling organizations.

By incorporating these predictors with normal priors centered at zero, the model balances complexity with interpretability, providing a nuanced view of the factors influencing candidate support. This approach enables us to evaluate how each factor contributes to variations in support predictions while maintaining flexibility to capture unique patterns within the data. The inclusion of weakly informative priors prevents overfitting and ensures that the model remains generalizable across different polling scenarios.

### Results

Our results are summarized in:

```{r}
#| label: linear-model
#| fig-cap: linear model analysis
#| echo: false
#| warning: false
#| message: false

# Load the Trump and Harris linear models
trump_linear_model <- readRDS(here::here("models", "Donald Trump_linear_model.rds"))
harris_linear_model <- readRDS(here::here("models", "Kamala Harris_linear_model.rds"))

# Load test data for Trump and Harris from Parquet files
trump_test <- read_parquet(here::here("data/02-analysis_data", "Donald Trump_test.parquet"))
harris_test <- read_parquet(here::here("data/02-analysis_data", "Kamala Harris_test.parquet"))

# Convert 'hypothetical' column to logical if it's not already logical
convert_to_logical <- function(df) {
  if ("hypothetical" %in% names(df) && !is.logical(df$hypothetical)) {
    df$hypothetical <- as.logical(df$hypothetical)
  }
  return(df)
}

# Make predictions using the linear models
trump_test$Predicted_Support <- predict(trump_linear_model, newdata = trump_test)
harris_test$Predicted_Support <- predict(harris_linear_model, newdata = harris_test)

# Combine predictions into a single dataframe for plotting
predictions_df <- data.frame(
  Candidate = c("Donald Trump", "Kamala Harris"),
  Predicted_Support = c(mean(trump_test$Predicted_Support), mean(harris_test$Predicted_Support))
)

# Create a pie chart for predicted support
pie_chart <- ggplot(predictions_df, aes(x = "", y = Predicted_Support, fill = Candidate)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = paste0(round(Predicted_Support, 1), "%")), 
            position = position_stack(vjust = 0.5), size = 5) +
  labs(title = "Average Predicted Support for Trump and Harris (Linear Model)") +
  theme_void() +
  scale_fill_manual(values = c("Donald Trump" = "skyblue", "Kamala Harris" = "salmon"))

# Print the pie chart
print(pie_chart)

# Prepare data for scatter plot of actual vs. predicted values
combined_test_data <- bind_rows(
  trump_test %>% select(Actual_Support = pct, Predicted_Support) %>% mutate(Candidate = "Donald Trump"),
  harris_test %>% select(Actual_Support = pct, Predicted_Support) %>% mutate(Candidate = "Kamala Harris")
)

# Create a scatter plot for actual vs. predicted support
scatter_plot <- ggplot(combined_test_data, aes(x = Actual_Support, y = Predicted_Support, color = Candidate)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") + # Reference line
  labs(title = "Actual vs. Predicted Support (Linear Model)",
       x = "Actual Support (%)",
       y = "Predicted Support (%)") +
  theme_minimal() +
  scale_color_manual(values = c("Donald Trump" = "skyblue", "Kamala Harris" = "salmon"))

# Print the scatter plot
print(scatter_plot)

```
## Bayesian Model set-up

Define $y_i$ as the support percentage (pct) for a candidate in the 2024 U.S. presidential election polls. This Bayesian model incorporates several predictors: $α_i$ (poll reliability score), $β_i$ (numeric grade indicating poll quality), $γ_i$ (transparency score of poll methodology), $δ_i$ (poll duration), $θ_i$ (sample size), $κ_i$ (type of population surveyed), $λ_i$ (whether the poll is hypothetical), and $μ_i$ (poll methodology type).

```{=tex}
\begin{align} 
y_i | \mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \times \phi_i + \beta_2 \times \beta_i + \beta_3 \times \gamma_i + \beta_4 \times \delta_i \\
      &\quad + \beta_5 \times \theta_i + \beta_6 \times \kappa_i + \beta_7 \times \lambda_i + \beta_8 \times \mu_i \\
\alpha &\sim \mbox{Normal}(0, 10) \\
\beta_j &\sim \mbox{Normal}(0, 2.5) \quad \text{for each } j = 1, \dots, 8 \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

```

We implemented this Bayesian model in R [@citeR] using the rstanarm package [@rstanarm], specifying weakly informative priors for regression coefficients to encapsulate reasonable uncertainty around the model parameters.

### Model justification

This Bayesian model is designed to estimate candidate support percentages in the 2024 U.S. presidential election by integrating various poll characteristics and methodological factors. The predictors, denoted by $\phi_i$, $\beta_i$, $\gamma_i$, $\delta_i$, $\theta_i$, $\kappa_i$, $\lambda_i$, and $\mu_i$, capture multiple dimensions of polling data that could impact candidate support levels.

The variable $\phi_i$ represents the poll reliability score, where higher scores suggest greater stability in support estimates. The predictors $\beta_i$ and $\gamma_i$ correspond to numeric grade and transparency score, which are both indicative of poll quality, likely contributing to more dependable support assessments. Additionally, poll duration ($\delta_i$) and sample size ($\theta_i$) reflect the 
scope and breadth of each poll, offering insights into the representativeness and consistency of the data. The variables $\kappa_i$, $\lambda_i$, and $\mu_i$ control for factors such as the population type surveyed, whether the poll is hypothetical, and the methodological specifics, allowing the model to account for differences across polling organizations.

By employing normal priors centered at zero for the regression coefficients, this Bayesian approach balances complexity and interpretability, enabling a nuanced understanding of each predictor’s contribution to candidate support variation. Weakly informative priors on coefficients prevent overfitting, supporting the model's generalizability across diverse polling scenarios while remaining sensitive to unique data patterns. This setup allows us to capture meaningful trends in candidate support and adjust for methodological variability among polls, providing robust insights for election forecasting."

### Results

<<<<<<< HEAD
Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```
=======
Our results are summarized in:
>>>>>>> 15d932b68ef20c88ef288ebba19468b185b47d9c

#######代码有问题暂时run不出来



# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```



\newpage


# References


