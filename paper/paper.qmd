---
title: "The 2024 U.S. Presidential Election Forecast"
subtitle: "Multiple Linear Regression and Bayesian Models Accounting for Poll Quality"
author: Haowei Fan, Fangning Zhang, Shaotong Li
thanks: "Code and data are available at: https://github.com/HaoweiFan0912/The-2024-U.S.-Presidential-Election-Forecast"
date: 13/10/2024
contact: haowei.fan@mail.utoronto.ca
licence: MIT
date-format: long
abstract: "This study presents a forecast for the 2024 U.S. presidential election using aggregated poll data to predict support for key candidates. By implementing both linear and Bayesian models, we analyze poll data from diverse sources to assess how factors related to poll quality influence candidate support predictions. Our findings reveal possible outcome of election. Additionally, this paper includes an idealized polling methodology to demonstrate best practices in survey design and sample representation."
format: pdf
number-sections: true
bibliography: references.bib
toc: true
toc-title: "Table of Contents"
toc-depth: 2
toc-location: left
---

```{r}
#| include: false
#| warning: false
#| message: false
library(tidyverse)
library(knitr)
library(dplyr)
library(ggplot2)
library(patchwork)
raw_data <- read_csv(here::here("data/01-raw_data/raw_data.csv"))
```


# Introduction

The U.S. presidential election is a globally significant event, drawing substantial international attention due to its potential impact on economies, international relations, and pressing social issues, including climate change and human rights. As the world anticipates the 2024 U.S. electoral contest, predicting the election’s possible outcomes can provide critical insights for policymakers, businesses, and civil society groups. This study aims to forecast the level of support for leading candidates, specifically Kamala Harris and Donald Trump, using aggregated poll data and statistical modeling.

To provide a robust prediction, we utilize a “poll-of-polls” approach, combining polling data from multiple organizations at both national and state levels to enhance accuracy and stability in forecasted support. Our analysis applies both a linear regression model and a Bayesian approach, with a focus on the key parameter of each candidate's predicted vote share. By considering variations in pollster methodology and geographic distinctions, we account for the nuances of state-level political landscapes and the potential influence of polling organizations.

The results of our models reveal consistent patterns in voter support across both Harris and Trump. The linear model estimates a stable support rate for Donald Trump at approximately 47.8%, with similar results for Harris at 46.7%. The Bayesian model, which incorporates pollster and state-level random effects, yields slightly more conservative support estimates, predicting 47.9% for Trump and 46.0% for Harris. These findings suggest that, while both candidates maintain stable support, Trump holds a slight advantage. The consistency across both models underlines the importance of accounting for variability across polling methodologies and regional voter bases.

Beyond the immediate electoral forecast, this study contributes valuable insights for understanding how polling predictions can inform societal and international expectations. Predicting election outcomes allows global stakeholders—such as policymakers, investors, and international organizations—to anticipate and adapt to potential shifts in U.S. policy. For instance, a leadership change could bring alterations in U.S. positions on trade, climate commitments, and foreign policy, influencing global economic stability and strategic alliances. Additionally, our findings underscore the importance of transparency in polling methodologies, as well as the potential for more nuanced and accurate forecasts that consider the heterogeneity in polling sources and voter demographics.

This paper is organized as follows. The next section outlines the data collection and filtering processes, detailing the key variables and sources. Following that, we discuss our methodological framework, including the construction of the linear and Bayesian models. In the results section, we present the outcomes of both models, and a discussion explores the broader implications of these findings. Finally, the paper concludes with recommendations for future research and potential applications of these forecasting models in electoral studies.

# Data {#sec-data}

## Overview

This project leverages several R packages[@citeR], including tidyverse[@tidyverse], rstanarm[@rstanarm], testthat[@testthat], readr[@readr], broom[@broom], ggplot2[@ggplot2], and posterior[@posterior], to clean, analyze, and visualize polling data for the 2024 U.S. presidential election forecast. The raw polling data was sourced from FiveThirtyEight's 2024 presidential election polls[@fivethirtyeight2024], providing a comprehensive foundation for our analysis. Together, these packages facilitate a reproducible approach to data handling, statistical modeling, and result presentation in this study.

## Raw data
raw data一共有52个variables，以及15891条样本。
去掉重复variables，以及无关紧要的url,还有全空的varibales后还剩下以下variables以及description。
部分重要的在此显示，不重要的在appendix。
```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| label: tbl-main_columns
#| tbl-cap: "Main column descriptions of the raw data"

# Define the selected variable names
selected_variables <- c("poll_id", "pollster_id", "sponsor_ids", "pollster_rating_id", "numeric_grade", "pollscore", "methodology", "transparency_score", "state", "start_date", "end_date", "sponsor_candidate_id", "sponsor_candidate_party", "question_id", "sample_size", "population", "tracking", "created_at", "notes", "source", "internal", "partisan", "race_id", "cycle", "office_type", "election_date", "stage", "nationwide_batch", "ranked_choice_reallocated", "ranked_choice_round", "hypothetical", "party", "answer", "pct")

# Define their descriptions
variable_descriptions <- c(
  "Unique identifier for each poll conducted.",
  "Unique identifier for the polling organization conducting the poll.",
  "Unique identifier(s) for the sponsor(s) of the poll, typically organizations that fund the poll.",
  "Unique identifier for the pollster's rating within a rating system.",
  "A numeric rating given to the pollster to indicate their quality or reliability .",
  "A numeric value representing the score or reliability of the pollster in question .",
  "The method used to conduct the poll .",
  "A score reflecting the pollster's transparency about their methodology .",
  "The U.S. state where the poll was conducted or focused, if applicable.",
  "The date the poll began .",
  "The date the poll ended .",
  "Unique identifier for the candidate sponsored by the sponsoring organization (if applicable).",
  "The political party of the candidate sponsored by the sponsor (if applicable).",
  "Unique identifier for the question asked in the poll.",
  "The total number of respondents participating in the poll .",
  "The abbreviated description of the respondent group, typically indicating their voting status .",
  "Indicates whether the poll is part of a tracking series .",
  "The timestamp when the poll data was created or entered into the system .",
  "Any additional notes or comments related to the poll.",
  "The source from where the poll data was derived.",
  "Indicates whether the poll is conducted internally by a campaign or organization.",
  "Indicates whether the poll has partisan sponsorship or is conducted by a partisan organization.",
  "A unique identifier for the political race being polled .",
  "The election cycle in which the poll is conducted .",
  "The type of political office being polled .",
  "The date of the election the poll is related to .",
  "The stage of the election being polled .",
  "Indicates whether the poll is part of a nationwide batch.",
  "Indicates if ranked-choice voting reallocations have been applied in the results.",
  "The round of ranked-choice voting, if applicable.",
  "Indicates whether the poll is about a hypothetical match-up.",
  "The political party of the candidate in the poll .",
  "The response or answer choice given in the poll .",
  "The percentage of the vote or support that the candidate received in the poll ."
)

# Create a tibble with variable names and descriptions
variable_tibble <- tibble(
  Variable = selected_variables,
  Description = variable_descriptions
)

# Define the variables to extract for the table of selected variables
variables_to_extract <- c("poll_id", "pollscore", "numeric_grade", "transparency_score", "start_date", "end_date", "sample_size", "population", "hypothetical", "methodology", "pct")

# Extract the relevant rows from the tibble
extracted_tibble <- variable_tibble %>% filter(Variable %in% variables_to_extract)

# Create the table using kable for selected variables
kable(extracted_tibble)
```
所有variable的na值
```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| label: tbl-variable_na
#| tbl-cap: "Number of Missing Values and Percentages for Variables"
# Calculate the number of missing values for each selected variable
na_counts <- sapply(raw_data[ , selected_variables], function(x) sum(is.na(x)))

# Calculate the percentage of missing values for each selected variable
na_percentages <- sapply(raw_data[ , selected_variables], function(x) mean(is.na(x)) * 100)

# Create a tibble for missing value counts and percentages
na_tibble <- tibble(
  Variable = names(na_counts),
  Missing_Values = na_counts,
  Percentage_Missing = round(na_percentages,2)
)

# Split the tibble into two halves for side-by-side display
na_tibble_1 <- na_tibble[1:ceiling(nrow(na_tibble)/2), ]
na_tibble_2 <- na_tibble[(ceiling(nrow(na_tibble)/2) + 1):nrow(na_tibble), ]

# Create the table using kable for missing values
kable(na_tibble)
```
重要的numerical variable的分布：
```{r, fig.pos="H", fig.width=22, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-numdis
#| fig-cap: "Distribution of numerical varibales"
### Define Variables and Prepare Data ###
# Define the numeric variables to plot
numeric_variables <- c("pollscore", "numeric_grade", "transparency_score", "sample_size", "pct")

# Convert start_date and end_date to Date type
raw_data$start_date <- ymd(raw_data$start_date)
raw_data$end_date <- ymd(raw_data$end_date)

# Define the date variables to plot
date_variables <- c("start_date", "end_date")

### Create Plots for Numeric Variables ###
# Create a list to store plots
plots <- list()

# Loop through selected numeric variables and plot their distributions
for (variable in numeric_variables) {
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(binwidth = 0.7, fill = "#69b3a2", color = "black", alpha = 0.8) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
    theme_minimal(base_size = 30) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 10),
      axis.text = element_text(size = 10)
    )
}

### Create Plots for Date Variables ###
# Loop through selected date variables and plot their distributions
for (variable in date_variables) {
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(binwidth = 30, fill = "#69b3a2", color = "black", alpha = 0.8) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
    theme_minimal(base_size = 30) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 10),
      axis.text = element_text(size = 10)
    )
}

### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 3, nrow = 3, heights = unit(rep(3, 4), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )

# Print the combined plot
print(combined_plot)

```
接下来是categorical
```{r, fig.pos="H", fig.width=22, fig.height=8}
#| warning: false
#| message: false
#| echo: false
#| label: fig-catdis
#| fig-cap: "Distribution of categorical varibales"

### Plot distributions for categorical variables ###
# Define the categorical variables to plot
categorical_variables <- setdiff(variables_to_extract, c(numeric_variables, "start_date", "end_date"))
categorical_variables <- categorical_variables[categorical_variables != "methodology" ]
categorical_variables <- categorical_variables[categorical_variables != "poll_id" ]
# Create a list to store plots for categorical variables
categorical_plots <- list()

# Loop through categorical variables and plot their distributions
for (variable in categorical_variables) {
  plot <- ggplot(raw_data, aes_string(x = variable)) +
    geom_bar(fill = "#69b3a2", color = "black") +
    labs(title = paste(variable), x = variable, y = "Count") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))
  
  # Add plot to list
  categorical_plots[[variable]] <- plot
}


### Plot top 5 methodologies ###
# Extract top 5 methodologies by frequency
top_5_methodologies <- raw_data %>%
  count(methodology, sort = TRUE) %>%
  top_n(5) %>%
  pull(methodology)

# Create a new column to categorize methodologies into top 5 and 'Other'
raw_data$methodology_grouped <- ifelse(raw_data$methodology %in% top_5_methodologies, raw_data$methodology, 'Other')

# Plot the distribution of the top 5 methodologies plus 'Other'
methodology_plot <- ggplot(raw_data, aes(x = methodology_grouped)) +
  geom_bar(fill = "#69b3a2", color = "black") +
  labs(title = "Top 5 Methodologies and Others", x = "Methodology", y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Add methodology plot to categorical plots list
categorical_plots[["methodology_grouped"]] <- methodology_plot


# Combine all individual plots for categorical variables into one using patchwork
combined_categorical_plot <- wrap_plots(categorical_plots) +
  plot_annotation(title = "Distributions of Categorical Variables")

# Print the combined plot for categorical variables
print(combined_categorical_plot)

### Create a list for non-numeric variables ###
non_numeric_variables <- setdiff(variables_to_extract, numeric_variables)

```
#######注意，appendix其他的图还没画




















## Measurement
	
This study uses polling data from FiveThirtyEight to capture public sentiment for the 2024 U.S. presidential election. Each observation in the dataset represents public support levels for key candidates as recorded by national and state-level polling organizations. Given the diversity in polling methodologies, question formats, and sampling techniques, the transformation of real-world opinions into structured data requires a standardized approach to ensure accuracy and comparability across sources.

The raw data underwent a comprehensive cleaning process to improve reliability. Initial filtering was applied to remove polls with missing key variables, such as support percentages, sample sizes, or poll ratings, ensuring that only complete and meaningful entries were retained. Duplicate entries were identified and eliminated to prevent redundancy. Polls with extreme support values or small sample sizes, which could introduce bias, were carefully reviewed and either adjusted or excluded based on consistency criteria.

Further, the data was standardized to unify variable formats and scales. Poll results reported in percentages were converted to decimal values, and state names were formatted consistently. After cleaning, the dataset was divided into training and test sets, with 70% allocated to training the model and 30% reserved for validation. This approach provided a robust dataset that accurately reflects public opinion trends, reducing the impact of inconsistencies across polling sources and supporting a reliable forecast of the 2024 U.S. presidential election.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.



Some of our data is of penguins (@fig-bills), from @palmerpenguins.

```{r}

```

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}

```

Talk way more about it. 

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.





















# Model

The goal of our modeling strategy is to estimate the support percentages for leading candidates in the 2024 U.S. presidential election, with a specific focus on Kamala Harris and Donald Trump. This approach accounts for potential variations in support across time, different pollsters, and geographic regions, ensuring a robust prediction framework that balances accuracy with interpretability. We implement both linear and Bayesian models to capture these patterns and examine the influence of polling quality and state-specific factors on the predicted support levels.

The linear model employs multiple regression, with candidate support percentage as the dependent variable and key predictors such as pollster rating, sample size, geographic region, and polling methodology. This model provides an interpretable framework, allowing us to assess the direct impact of each factor on candidate support. However, to account for more nuanced, hierarchical patterns within the data, we extend this analysis using a Bayesian framework.

The Bayesian model incorporates pollster and state-level random effects, enabling us to model variations across different polling organizations and geographic areas more effectively. By including weakly informative priors, the Bayesian model offers greater flexibility while controlling for overfitting, providing a more comprehensive view of voter support trends. Together, these models create a reliable foundation for forecasting support in the 2024 election, with each approach highlighting distinct aspects of the polling data.

## linear Model set-up

Define $y_i$ as the support percentage (pct) for a candidate in the 2024 U.S. presidential election polls. The linear model includes several predictors: $α_i$ (poll reliability score), $β_i$ (numeric grade indicating poll quality), $γ_i$ (transparency score of poll methodology), $δ_i$ (poll duration), $θ_i$ (sample size), $κ_i$ (type of population surveyed), $λ_i$ (whether the poll is hypothetical), and $μ_i$ (poll methodology type).

The model is specified as follows:

```{=tex}

\begin{align} 
y_i | \mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \times \phi_i + \beta_2 \times \beta_i + \beta_3 \times \gamma_i + \beta_4 \times \delta_i \\
      &\quad + \beta_5 \times \theta_i + \beta_6 \times \kappa_i + \beta_7 \times \lambda_i + \beta_8 \times \mu_i \\
\alpha &\sim \mbox{Normal}(0, 10) \\
\beta_j &\sim \mbox{Normal}(0, 2.5) \quad \text{for each } j = 1, \dots, 8 \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

```
We run the model in R [@citeR] using the lm() for linear regression, along with tidyverse [@tidyverse] for data manipulation and visualization.

### Model Justification

This linear model aims to estimate candidate support percentages in the 2024 U.S. presidential election by accounting for various poll characteristics and methodological factors. The model includes multiple predictors, represented by $φ_i$, $β_i$, $γ_i$, $δ_i$, $θ_i$, $κ_i$, $λ_i$, and $μ_i$, each of which captures different aspects of the polling data that may impact candidate support.

The variable $φ_i$ represents poll reliability scores, with higher values expected to correlate with more stable support estimates. Similarly, $β_i$ and $γ_i$ denote quality-related factors such as numeric grade and transparency score, which likely influence the reliability of the polls. Poll duration ($δ_i$) and sample size ($θ_i$) add further depth to the model by reflecting the scope and stability of each poll's data. The variables $κ_i$, $λ_i$, and $μ_i$ account for population type, the hypothetical nature of the poll, and poll methodology, respectively, allowing the model to adjust for methodological differences across polling organizations.

By incorporating these predictors with normal priors centered at zero, the model balances complexity with interpretability, providing a nuanced view of the factors influencing candidate support. This approach enables us to evaluate how each factor contributes to variations in support predictions while maintaining flexibility to capture unique patterns within the data. The inclusion of weakly informative priors prevents overfitting and ensures that the model remains generalizable across different polling scenarios.

### Results

Our results are summarized in:

```{r}
#| label: linear-model
#| fig-cap: linear model analysis
#| echo: false
#| warning: false
#| message: false

# Load the Trump and Harris linear models
trump_linear_model <- readRDS(here::here("models", "Donald Trump_linear_model.rds"))
harris_linear_model <- readRDS(here::here("models", "Kamala Harris_linear_model.rds"))

# Load test data for Trump and Harris from Parquet files
trump_test <- read_parquet(here::here("data/02-analysis_data", "Donald Trump_test.parquet"))
harris_test <- read_parquet(here::here("data/02-analysis_data", "Kamala Harris_test.parquet"))

# Convert 'hypothetical' column to logical if it's not already logical
convert_to_logical <- function(df) {
  if ("hypothetical" %in% names(df) && !is.logical(df$hypothetical)) {
    df$hypothetical <- as.logical(df$hypothetical)
  }
  return(df)
}

# Make predictions using the linear models
trump_test$Predicted_Support <- predict(trump_linear_model, newdata = trump_test)
harris_test$Predicted_Support <- predict(harris_linear_model, newdata = harris_test)

# Combine predictions into a single dataframe for plotting
predictions_df <- data.frame(
  Candidate = c("Donald Trump", "Kamala Harris"),
  Predicted_Support = c(mean(trump_test$Predicted_Support), mean(harris_test$Predicted_Support))
)

# Create a pie chart for predicted support
pie_chart <- ggplot(predictions_df, aes(x = "", y = Predicted_Support, fill = Candidate)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = paste0(round(Predicted_Support, 1), "%")), 
            position = position_stack(vjust = 0.5), size = 5) +
  labs(title = "Average Predicted Support for Trump and Harris (Linear Model)") +
  theme_void() +
  scale_fill_manual(values = c("Donald Trump" = "skyblue", "Kamala Harris" = "salmon"))

# Print the pie chart
print(pie_chart)

# Prepare data for scatter plot of actual vs. predicted values
combined_test_data <- bind_rows(
  trump_test %>% select(Actual_Support = pct, Predicted_Support) %>% mutate(Candidate = "Donald Trump"),
  harris_test %>% select(Actual_Support = pct, Predicted_Support) %>% mutate(Candidate = "Kamala Harris")
)

# Create a scatter plot for actual vs. predicted support
scatter_plot <- ggplot(combined_test_data, aes(x = Actual_Support, y = Predicted_Support, color = Candidate)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") + # Reference line
  labs(title = "Actual vs. Predicted Support (Linear Model)",
       x = "Actual Support (%)",
       y = "Predicted Support (%)") +
  theme_minimal() +
  scale_color_manual(values = c("Donald Trump" = "skyblue", "Kamala Harris" = "salmon"))

# Print the scatter plot
print(scatter_plot)

```
## Bayesian Model set-up

Define $y_i$ as the support percentage (pct) for a candidate in the 2024 U.S. presidential election polls. This Bayesian model incorporates several predictors: $α_i$ (poll reliability score), $β_i$ (numeric grade indicating poll quality), $γ_i$ (transparency score of poll methodology), $δ_i$ (poll duration), $θ_i$ (sample size), $κ_i$ (type of population surveyed), $λ_i$ (whether the poll is hypothetical), and $μ_i$ (poll methodology type).

```{=tex}
\begin{align} 
y_i | \mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \times \phi_i + \beta_2 \times \beta_i + \beta_3 \times \gamma_i + \beta_4 \times \delta_i \\
      &\quad + \beta_5 \times \theta_i + \beta_6 \times \kappa_i + \beta_7 \times \lambda_i + \beta_8 \times \mu_i \\
\alpha &\sim \mbox{Normal}(0, 10) \\
\beta_j &\sim \mbox{Normal}(0, 2.5) \quad \text{for each } j = 1, \dots, 8 \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

```

We implemented this Bayesian model in R [@citeR] using the rstanarm package [@rstanarm], specifying weakly informative priors for regression coefficients to encapsulate reasonable uncertainty around the model parameters.

### Model justification

This Bayesian model is designed to estimate candidate support percentages in the 2024 U.S. presidential election by integrating various poll characteristics and methodological factors. The predictors, denoted by $\phi_i$, $\beta_i$, $\gamma_i$, $\delta_i$, $\theta_i$, $\kappa_i$, $\lambda_i$, and $\mu_i$, capture multiple dimensions of polling data that could impact candidate support levels.

The variable $\phi_i$ represents the poll reliability score, where higher scores suggest greater stability in support estimates. The predictors $\beta_i$ and $\gamma_i$ correspond to numeric grade and transparency score, which are both indicative of poll quality, likely contributing to more dependable support assessments. Additionally, poll duration ($\delta_i$) and sample size ($\theta_i$) reflect the 
scope and breadth of each poll, offering insights into the representativeness and consistency of the data. The variables $\kappa_i$, $\lambda_i$, and $\mu_i$ control for factors such as the population type surveyed, whether the poll is hypothetical, and the methodological specifics, allowing the model to account for differences across polling organizations.

By employing normal priors centered at zero for the regression coefficients, this Bayesian approach balances complexity and interpretability, enabling a nuanced understanding of each predictor’s contribution to candidate support variation. Weakly informative priors on coefficients prevent overfitting, supporting the model's generalizability across diverse polling scenarios while remaining sensitive to unique data patterns. This setup allows us to capture meaningful trends in candidate support and adjust for methodological variability among polls, providing robust insights for election forecasting."

### Results

Our results are summarized in:

#######代码有问题暂时run不出来



# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details
raw data 部分没有解释的varibale
```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| label: tbl-remain_columns
#| tbl-cap: "Remaining column descriptions of the raw data"

# Define the variables to extract for the remaining variables
remaining_variables <- setdiff(selected_variables, variables_to_extract)

# Extract the relevant rows from the tibble for remaining variables
remaining_tibble <- variable_tibble %>% filter(Variable %in% remaining_variables)

# Create the table using kable for remaining variables
kable(remaining_tibble, caption = "Descriptions of Remaining Variables")
```
raw data里没画的图
```{r}
#to be done
```




# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}

```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}

```



\newpage


# References


