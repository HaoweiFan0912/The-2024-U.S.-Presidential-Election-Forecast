---
title: "Forecasting the 2024 U.S. Presidential Election: Comparative Support Analysis of Kamala Harris and Donald Trump"
subtitle: "Predictive Models Indicate a Narrow Advantage for Harris in a Closely Contested Race"
author: 
  - Haowei Fan
  - Fangning Zhang
  - Shaotong Li
thanks: "Code and data are available at: [https://github.com/HaoweiFan0912/US_Election-Forecast/tree/main]."
date: today
date-format: long
abstract: "This study aggregates polling data to forecast support for 2024 U.S. presidential candidates Kamala Harris and Donald Trump. By applying linear models with adjustments, we identify a modest lead for Harris at 47.6% over Trump’s 43.5%. The findings highlight that carefully weighted polling data provides a clearer view of electoral dynamics, showing how rigorous methodology in forecasting can yield more accurate insights into public opinion trends, aiding informed decision-making in political and economic spheres."
format: pdf
toc: true           
toc-title: "Table of Contents" 
toc-depth: 2    
number_sections: true    
bibliography: references.bib
---
```{r}
#| include: false
#| warning: false
#| message: false
#| echo: false
#### Workspace setup ####
library(tidyverse)
library(knitr)
library(dplyr)
library(arrow)
library(patchwork)
library(car)
library(kableExtra)
library(gridExtra)
library(moments)
library(grid)
set.seed(912)
#### Read data ####
raw_data <- read_csv(here::here("data/01-raw_data/raw_data.csv"))
train_Trump <- read_parquet(here::here("data/02-analysis_data/01-training/train_Trump.parquet"))
train_Harris <- read_parquet(here::here("data/02-analysis_data/01-training/train_Harris.parquet"))
test_Trump <- read_parquet(here::here("data/02-analysis_data/02-testing/test_Trump.parquet"))
test_Harris <- read_parquet(here::here("data/02-analysis_data/02-testing/test_Harris.parquet"))
full_Trump <- read_parquet(here::here("data/02-analysis_data/00-full/full_Trump.parquet"))
full_Harris <- read_parquet(here::here("data/02-analysis_data/00-full/full_Harris.parquet"))
Trump_model <- readRDS(here::here("models/Trump_model.rds"))
Harris_model <- readRDS(here::here("models/Harris_model.rds"))
```

# Introduction
The U.S. presidential election has profound implications on a global scale, shaping international relations, economic policy, and key social issues. As the 2024 election approaches, the ability to accurately forecast potential outcomes is essential for policymakers, businesses, and organizations seeking to anticipate shifts in U.S. policy that may affect trade, climate commitments, and strategic alliances [@citeBBC]. Additionally, recent analyses suggest that the election could introduce volatility into financial markets, emphasizing the importance of reliable predictions for strategic planning [@citeEuronews]. However, predicting election outcomes presents significant challenges due to a multitude of influencing factors, such as media influence, public sentiment, and socio-political dynamics, which collectively add complexity to election forecasting [@citeOregon]. Past elections further illustrate that targeted messaging and political events can profoundly impact voter behavior, complicating predictions even further [@citeYale].

This study seeks to address these complexities by examining voter support for the 2024 presidential candidates Kamala Harris and Donald Trump. While substantial polling data exists, current aggregation methods often lack consistency and fail to adequately consider critical factors such as poll reliability and sample size, leading to unreliable predictions. To address this gap, the present study adopts a “poll-of-polls” methodology, drawing from multiple data sources at both national and state levels. Through the application of multiple linear regression models, the study integrates essential variables, including pollster reliability, sample size, and polling duration, to produce a forecast that is both stable and transparent.

The estimand in this study represents the expected level of voter support for each primary candidate, Kamala Harris and Donald Trump, based on aggregated polling data across diverse demographics and polling methodologies. This measure aims to capture the central tendency of public opinion, adjusted for polling reliability and sample characteristics, to provide a stable estimate of each candidate's projected support under current conditions. By centering on this estimand, the analysis offers a robust and interpretable forecast applicable for strategic decision-making in both political and economic contexts.

The findings suggest a slight advantage for Harris, with a predicted support level of 47.6% compared to Trump’s 43.5%. This marginal lead underscores the importance of methodological rigor, as systematically weighting data by reliability yields more consistent and interpretable predictions. The results indicate that while both candidates retain substantial support, polling methods and demographic representation can subtly shift the support dynamics, providing a deeper understanding of the electoral landscape beyond basic polling figures.

This paper is structured as follows: first, the data collection and filtering processes are outlined, followed by a description of the methodological framework, introducing linear modeling approaches. The results are then presented and analyzed, with a discussion on broader implications. The paper concludes with recommendations for future research and potential applications of these forecasting models in electoral studies.

This project leverages several R packages, including tidyverse[@citeTidyverse], janitor[@citeJanitor], tidyr[@citeTidyr], dplyr[@citeDplyr], lubridate[@citeLubridate], arrow[@citeArrow], patchwork[@citePatchwork], car[@citeCar], kableExtra[@citeKableExtra], gridExtra[@citeGridExtra], moments[@citeMoments], grid[@citeGrid], rstanarm[@citeRstanarm], and testthat[@citeTestthat], to clean, organize, analyze, and visualize data in forecasting voter support for the 2024 U.S. presidential election. These packages support a reproducible and rigorous approach to data management, statistical modeling, and result presentation, ensuring transparency and accuracy throughout the analysis process.
 【最后改结构描述加cross-reference】


# Data {#sec-data}

## Overview
The dataset comes from FiveThirtyEight's 'Presidential Election Polls (Current Cycle)' (Ryan Best and Wiederkehr, 2024). FiveThirtyEight is a well-known website recognized for its political, economic, and sports analyses. Its polling aggregation methodology is highly regarded in the field, aiming to provide readers with transparent, scientific, and as accurate as possible predictions. This polling data is compiled from various polling agencies, encompassing a wide range of demographic information, which serves as an essential basis for analyzing public voting preferences in the upcoming presidential election.

The analysis and visualizations in this paper are based on polling results as of October 22. The dataset includes 52 variables and 17,133 samples from various polling sources, asking participants who they support in the upcoming presidential election. To ensure accuracy and consistency, the data has been carefully processed and cleaned to remove biases and guarantee data integrity and comparability.

This project leverages several R packages, including tidyverse[@tidyverse], rstanarm[@rstanarm], testthat[@testthat], readr[@readr], broom[@broom], ggplot2[@ggplot2], and posterior[@posterior], to clean, analyze, and visualize polling data for the 2024 U.S. presidential election forecast. These packages facilitate a reproducible approach to data handling, statistical modeling, and result presentation in this study.

## Raw data
Raw data 一共包含了52个variable以及17133个sample.
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-vord
#| tbl-cap: "Varibales of raw data"

# Get the column names and arrange them into multiple columns
column_names <- names(raw_data)
num_columns <- 3  # Set the desired number of columns
num_rows <- ceiling(length(column_names) / num_columns)
matrix_data <- matrix(c(column_names, rep("", num_columns * num_rows - length(column_names))), 
                      nrow = num_rows, byrow = TRUE)

# Convert the matrix to a data frame and format it with kable, set font size, and adjust header styling to remove extra row
kable(as.data.frame(matrix_data), 
      col.names = NULL)
```
其中重要的variables，其余的在appdendix
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-ivatd
#| tbl-cap: "Important variables and their descriptions"

variable_descriptions <- data.frame(
  Variable = c("poll_id", "methodology", "population", "ranked_choice_reallocated",
               "hypothetical", "answer", "numeric_grade", "pollscore", 
               "transparency_score", "start_date", "end_date", "sample_size", "pct"),
  Description = c(
    "Unique identifier for each poll conducted.",
    "The method used to conduct the poll (e.g., Online Panel).",
    "The abbreviated description of the respondent group, typically indicating their voting status (e.g., 'lv' for likely voters).",
    "Indicates if ranked-choice voting reallocations have been applied in the results.",
    "Indicates whether the poll is about a hypothetical match-up.",
    "The response or answer choice given in the poll (e.g., the candidate's party).",
    "A numeric rating given to the pollster to indicate their quality or reliability (e.g., 3.0).",
    "A numeric value representing the score or reliability of the pollster in question (e.g., -1.1).",
    "A score reflecting the pollster's transparency about their methodology (e.g., 9.0).",
    "The date the poll began (e.g., 10/8/24).",
    "The date the poll ended (e.g., 10/11/24).",
    "The total number of respondents participating in the poll (e.g., 2712).",
    "The percentage of the vote or support that the candidate received in the poll (e.g., 51.0 for Kamala Harris)."
  )
)

# Create the table using kable
kable(variable_descriptions) %>%
  kable_styling() %>%
  column_spec(1, width = "4.5cm") %>% # Adjust the width of the first column
  column_spec(2, width = "10cm")    # Adjust the width of the second column
```
52个varibles中以下几个与我们的project明显无关，我们在此不做讨论：
"notes", "url", "url_article", "url_topline", "url_crosstab", "source"
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
del_1 <- c("notes", "url", "url_article", "url_topline", "url_crosstab", "source")
droped_data <- raw_data %>% select(-any_of(del_1))
```
此外，还有一些相同的variables，我们保留其一，剩下的也不做讨论，它们包括："pollster", "sponsors", "display_name", "pollster_rating_name", "sponsor_candidate", "endorsed_candidate_name", "population_full", "candidate_id", "candidate_name"
```{r}
#| warning: false
#| message: false
#| echo: false
# 这里需要画一个table，展示删除的重复变量
del_2 <- c("pollster", "sponsors", "display_name", "pollster_rating_name", "sponsor_candidate", "endorsed_candidate_name",
           "population_full", "candidate_id", "candidate_name")
droped_data <- droped_data %>% select(-any_of(del_2))
```
常数变量我们也不做讨论，因为无法影响我们的预测，它们是：
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-cv
#| tbl-cap: "Constant variables"
# Identify variables where all values are the same (including NA)
same_value_variables <- names(droped_data)[sapply(droped_data, function(x) length(unique(x)) == 1)]
# Create a data frame with variables and their unique values
same_value_data <- data.frame(Variable = same_value_variables, Value = sapply(same_value_variables, function(var)
unique(na.omit(droped_data[[var]]))[1]))
# Print the names of variables with all identical values using kable
kable(same_value_data[, 2, drop = FALSE], col.names = c("Variable", "Value"))
del_4 <- c("endorsed_candidate_id", "endorsed_candidate_party", "subpopulation", "cycle", "election_date", "stage", "nationwide_batch", 
           "office_type", "seat_number", "seat_name")
droped_data <- droped_data %>% select(-any_of(del_4))
```
其中categorical的有"poll_id", "pollster_id", "sponsor_ids", "pollster_rating_id", "methodology", "state",
         "sponsor_candidate_id", "sponsor_candidate_party", "question_id", "population", "tracking", "created_at", "internal",
         "partisan","race_id", "ranked_choice_reallocated", "ranked_choice_round", "hypothetical","party","answer"
```{r}
#| warning: false
#| message: false
#| echo: false
catego <- c("poll_id", "pollster_id", "sponsor_ids", "pollster_rating_id", "methodology", "state",
         "sponsor_candidate_id", "sponsor_candidate_party", "question_id", "population", "tracking", "created_at", "internal",
         "partisan","race_id", "ranked_choice_reallocated", "ranked_choice_round", "hypothetical","party","answer")
```
重要的categorical为下面的，剩下的将在appendix阐述："poll_id", "methodology", "population", "ranked_choice_reallocated", "hypothetical","answer"
```{r}
#| warning: false
#| message: false
#| echo: false
catego_inp <- c("poll_id", "methodology", "population", "ranked_choice_reallocated", "hypothetical","answer")
```
一共有3530个poll
```{r}
#| warning: false
#| message: false
#| echo: false
# Get unique Poll IDs and print the count
unique_poll_ids <- unique(raw_data$poll_id)
```
描述
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: fig-bv
#| fig-cap: "Boolean variables"

# Create a list to store the plots
plots <- list()

# Bar chart for 'ranked_choice_reallocated' with count labels
plots[["ranked_choice"]] <- ggplot(raw_data, aes(x = ranked_choice_reallocated)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  geom_text(stat = "count", aes(label = after_stat(count)), vjust = -0.5, size = 4) +  # Updated count label notation
  labs(title = "Bar Chart of Ranked Choice Reallocated", x = "Ranked Choice Reallocated", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  ) +
  ylim(0, max(table(raw_data$ranked_choice_reallocated)) * 1.2)  # Increase y-axis limit to fit labels

# Bar chart for 'hypothetical' with count labels
plots[["hypothetical"]] <- ggplot(raw_data, aes(x = hypothetical)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  geom_text(stat = "count", aes(label = after_stat(count)), vjust = -0.5, size = 4) +  # Updated count label notation
  labs(title = "Bar Chart of Hypothetical", x = "Hypothetical", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  ) +
  ylim(0, max(table(raw_data$hypothetical)) * 1.2)  # Increase y-axis limit to fit labels

# Combine and print the plots using patchwork
combined_plot <- wrap_plots(plots, ncol = 2) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )

# Print the combined plot
print(combined_plot)

```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-cv
#| fig-cap: "Catogorical variables"

# Create a list to store the plots
plots <- list()

# Top 3 Methodologies with 'Other' grouped
methodology_counts <- sort(table(raw_data$methodology), decreasing = TRUE)
top_3_methodologies <- names(methodology_counts)[1:3]
raw_data$methodology_grouped <- ifelse(raw_data$methodology %in% top_3_methodologies, raw_data$methodology, "Other")

# Create horizontal bar chart for 'methodology'
plots[["methodology"]] <- ggplot(raw_data, aes(x = methodology_grouped)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  geom_text(stat = "count", aes(label = after_stat(count)), hjust = -0.2, size = 9) +  # Larger count labels
  labs(title = "Top 3 Methodologies and Others", x = "Count", y = "Methodology") +
  theme_minimal(base_size = 24) +  # Increase base size for all text elements
  theme(
    plot.title = element_text(hjust = 0.5, size = 32, face = "bold"),  # Title font size
    axis.title = element_text(size = 28),  # Axis title font size
    axis.text = element_text(size = 24)  # Axis text font size
  ) +
  coord_flip()

# Population bar chart
plots[["population"]] <- ggplot(raw_data, aes(x = population)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  geom_text(stat = "count", aes(label = after_stat(count)), hjust = -0.2, size = 9) +  # Larger count labels
  labs(title = "Population", x = "Count", y = "Population") +
  theme_minimal(base_size = 24) +  # Increase base size for all text elements
  theme(
    plot.title = element_text(hjust = 0.5, size = 32, face = "bold"),  # Title font size
    axis.title = element_text(size = 28),  # Axis title font size
    axis.text = element_text(size = 24)  # Axis text font size
  ) +
  coord_flip()

# Top 3 Answers with 'Other' grouped
answer_counts <- sort(table(raw_data$answer), decreasing = TRUE)
top_3_answer <- names(answer_counts)[1:3]
raw_data$answer <- ifelse(raw_data$answer %in% top_3_answer, raw_data$answer, "Other")

# Create horizontal bar chart for 'answer'
plots[["answer"]] <- ggplot(raw_data, aes(x = answer)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  geom_text(stat = "count", aes(label = after_stat(count)), hjust = -0.2, size = 9) +  # Larger count labels
  labs(title = "Top 3 Answers and Others", x = "Count", y = "Answer") +
  theme_minimal(base_size = 24) +  # Increase base size for all text elements
  theme(
    plot.title = element_text(hjust = 0.5, size = 32, face = "bold"),  # Title font size
    axis.title = element_text(size = 28),  # Axis title font size
    axis.text = element_text(size = 24)  # Axis text font size
  ) +
  coord_flip()

# Combine the plots using patchwork
combined_plot <- wrap_plots(plots, ncol = 1) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 32)
    )
  )

# Print the combined plot
print(combined_plot)

```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-donvp1
#| fig-cap: "Distribution of numerical varibales part 1"

### Create Plots for Numeric Variables ###
# Create a list to store plots
plots <- list()

# Loop through selected numeric variables and plot their distributions with a line connecting bar tops
for (variable in names(numer %>% select(numeric_grade, pollscore, transparency_score))) {
  # Calculate bin counts and midpoints
  bin_data <- ggplot_build(
    ggplot(raw_data, aes_string(x = variable)) +
      geom_histogram(binwidth = 0.5)
  )$data[[1]]
  
  # Calculate the midpoint of each bin for line plotting
  bin_data <- bin_data %>%
    mutate(midpoint = (xmin + xmax) / 2)
  
  # Create histogram plot with line connecting the bar tops
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(binwidth = 0.5, fill = "#69b3a2", color = "black", alpha = 0.8) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
    theme_minimal(base_size = 24) +  # Adjusted base font size for readability
    theme(
      plot.title = element_text(hjust = 0.5, size = 35, face = "bold"),  # Larger title font size
      axis.title = element_text(size = 35),  # Axis title font size
      axis.text = element_text(size = 35)  # Axis text font size
    )
}

### Combine and Print Plots ###
# Combine all individual plots into one vertical layout
combined_plot <- wrap_plots(plots, ncol = 1) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 35)
    )
  )

# Print the combined plot
print(combined_plot)

```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-donvp2
#| fig-cap: "Distribution of numerical varibales part 2"

### Create Plots for Numeric Variables ###
# Create a list to store plots
plots <- list()

# Loop through selected numeric variables and plot their distributions
for (variable in names(numer %>% select(sample_size, pct))) {
  if (variable == "sample_size") {
    # For sample_size, focus on the range 0-20000
    plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
      geom_histogram(binwidth = 500, fill = "#69b3a2", color = "black", alpha = 0.8) +
      xlim(0, 10000) +  # Set x-axis limits to focus on 0-10000 range
      labs(title = "Distribution of Sample Size (0-10000)", x = variable, y = "Frequency") +
      theme_minimal(base_size = 24) +
      theme(
        plot.title = element_text(hjust = 0.5, size = 35, face = "bold"),  # Larger title font size
        axis.title = element_text(size = 30),  # Larger axis title font size
        axis.text = element_text(size = 28)  # Larger axis text font size
      )
  } else {
    # For other variables, keep the full range
    plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
      geom_histogram(binwidth = 5, fill = "#69b3a2", color = "black", alpha = 0.8) +
      labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
      theme_minimal(base_size = 24) +
      theme(
        plot.title = element_text(hjust = 0.5, size = 35, face = "bold"),  # Larger title font size
        axis.title = element_text(size = 30),  # Larger axis title font size
        axis.text = element_text(size = 28)  # Larger axis text font size
      )
  }
}

### Combine and Print Plots ###
# Combine all individual plots into one vertical layout
combined_plot <- wrap_plots(plots, ncol = 1) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 35)
    )
  )

# Print the combined plot
print(combined_plot)

```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-dodv
#| fig-cap: "Distribution of date varibales"

### Define Variables and Prepare Data ###
# Convert start_date and end_date to Date type
raw_data$start_date <- ymd(raw_data$start_date)
raw_data$end_date <- ymd(raw_data$end_date)

# Define the date variables to plot
date_variables <- c("start_date", "end_date")

### Create Plots for Date Variables ###
# Create a list to store plots
plots <- list()

# Loop through selected date variables and plot their distributions with a density curve
for (variable in date_variables) {
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(fill = "#69b3a2", color = "black", alpha = 0.8) +  # Keep the original binwidth
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
    theme_minimal(base_size = 24) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 35, face = "bold"),  # Larger title font size
      axis.title = element_text(size = 30),  # Larger axis title font size
      axis.text = element_text(size = 28)  # Larger axis text font size
    )
}

### Combine and Print Plots ###
# Arrange the plots vertically without changing their individual orientation
combined_plot <- wrap_plots(plots, ncol = 1) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 35)
    )
  )

# Print the combined plot
print(combined_plot)

```
## Cleaned data
In the raw data, we initially identified a total of 52 variables. Some of these variables, such as 'url', are clearly unrelated to the objectives of this project. There are also constant variables, such as 'election_date', which consistently contains the value '11/5/24'. Additionally, we found duplicate variables conveying the same information, like 'pollster_id' and 'pollster'. Therefore, we first removed these irrelevant and redundant variables. The remaining variables are as follows:
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-rv
#| tbl-cap: "Remained variables"

# Get the column names and arrange them into multiple columns
column_names <- names(droped_data)
num_columns <- 3  # Set the desired number of columns
num_rows <- ceiling(length(column_names) / num_columns)
matrix_data <- matrix(c(column_names, rep("", num_columns * num_rows - length(column_names))), 
                      nrow = num_rows, byrow = TRUE)

# Convert the matrix to a data frame and format it with kable, set font size, and adjust header styling to remove extra row
kable(as.data.frame(matrix_data), 
      col.names = NULL)
```
Next, we calculated the percentage of missing values for each variable across the entire dataset. We then removed all variables with more than 40% missing values. These variables, along with their respective proportions of missing values, are as follows:
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-vwbpomv
#| tbl-cap: "Variables with big porpotion of missing values"
na_proportions <- sapply(names(droped_data), function(var) {
  round(mean(is.na(raw_data[[var]])), 2)
})

# Create a data frame with variable names and their NA proportions
na_proportions_data <- data.frame(Variable = names(droped_data), NA_Proportion = na_proportions)

# Filter variables with NA proportion greater than 40%
high_na_proportions <- na_proportions_data[na_proportions_data$NA_Proportion > 0.4, ]

# Print the NA proportions greater than 40% using kable
kable(high_na_proportions[, 2, drop = FALSE], col.names = c("Variable", "NA Proportion"))

del_5 <- c("sponsor_ids", "state", "sponsor_candidate_id", "sponsor_candidate_party", "tracking",
           "internal","partisan","ranked_choice_round")
droped_data <- droped_data %>% select(-any_of(del_5))

```
Since the influence of pollsters can be quantified using their ratings, such as 'numeric_grade', 'pollscore', and 'transparency_score', we removed these variables to simplify the dataset and the model. Similarly, 'created_at' was also removed due to its strong correlation with 'start_date'. 
```{r}
#| warning: false
#| message: false
#| echo: false
del_6 <- c("pollster_id", "pollster_rating_id", "created_at")
droped_data <- droped_data %>% select(-any_of(del_6))
```
Finally, due to the limitations of our model, we removed 'race_id', 'party', and 'question_id'. The reason for this is that we will extract and analyze the data for each candidate individually, which makes 'race_id' and 'party' constant within the corresponding dataset. Additionally, 'question_id' contains 6,421 unique values, making it unsuitable for categorization, and we removed it to avoid overfitting the model.
```{r}
#| warning: false
#| message: false
#| echo: false
# Get unique Question IDs and print the count
unique_question_ids <- unique(raw_data$question_id)
```
Finally, the remaining variables are as follows:
```{r, fig.height=30, fig.width=30}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-fv
#| tbl-cap: "Final variables"
final <- c("poll_id","numeric_grade","pollscore","methodology","transparency_score","sample_size","population", 
           "ranked_choice_reallocated", "hypothetical", "answer","pct","start_date", "end_date")

# Get the column names and arrange them into multiple columns
column_names <- final
num_columns <- 3  # Set the desired number of columns
num_rows <- ceiling(length(column_names) / num_columns)
matrix_data <- matrix(c(column_names, rep("", num_columns * num_rows - length(column_names))), 
                      nrow = num_rows, byrow = TRUE)

# Convert the matrix to a data frame and format it with kable, set font size, and adjust header styling to remove extra row
kable(as.data.frame(matrix_data), 
      col.names = NULL)
```
After finalizing the variables, we first created a new variable named 'duration', which replaced 'start_date' and 'end_date'. This new variable represents the number of days between 'start_date' and 'end_date'.Next, we categorized the 51 different methodologies into four levels, ranging from the least reliable and accurate (level_1) to the most reliable (level_4). 

Subsequently, we handled the missing values by imputing numerical variables with their mean values and categorical variables with their mode. Since our results are not exact percentages, we used 'score' to name what would typically be called 'pct'. We then finalize and tidy up the variable names.

Next, we extracted the data for each candidate individually. We calculated a weighted score by weighting according to the number of times each candidate was mentioned in the polls. After comparison, we observed that the top three candidates—Trump, Harris, and Biden—had significantly higher scores than the remaining candidates. Given that Biden has withdrawn from the race, we are now focusing only on the datasets for Trump and Harris for further analysis. 

Next, we split the data for Trump and Harris into a training set (70%) and a test set (30%). These four datasets form our analysis data. Below is a portion of the Trump training set for reference:
```{r, fig.height=30, fig.width=60}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-eoad
#| tbl-cap: "Example of analysis data"
kable(head(train_Trump), col.names = names(train_Trump))
```
## Measurement
The method used to forecast the presidential election results is the poll-of-polls, which aggregates results from multiple polls instead of relying on a single survey, aiming to make the results more accurate and stable. In this method, each poll is assigned a weight based on factors such as sample size, recency, and the pollster’s historical accuracy. 

The dataset used for this prediction is from FiveThirtyEight, which includes scientifically sound public polls that meet methodological standards. Polling organizations are rated based on accuracy, transparency, and sample quality, represented by a numeric_grade (ranging from 0.5 to 3.0). Higher scores indicate greater reliability. The histogram of numeric_grade values shows a concentration around scores of 2 and 3, suggesting most pollsters are of moderate to good quality.

Polling organizations use different survey methods but follow similar principles. They select representative samples, publish surveys through chosen platforms, and aim to ask clear, unbiased questions. YouGov, discussed in the appendix, is one such example.

Survey data accuracy is limited by several factors. Sampling bias can lead to an unrepresentative sample, underrepresenting certain demographics. Response bias may occur if participants are not truthful or are influenced by question phrasing. Platform differences also impact reliability, as social media polls may attract different audiences compared to phone or in-person surveys. Pollscore and numeric grade filters help ensure quality, but they are based on historical data and may not reflect current survey quality. Additionally, the rapidly changing political narrative and voter sentiment during campaigns can affect polling accuracy. These factors contribute to inaccuracies in survey results, affecting the reliability of aggregated data.


## Similar dataset

# Model

## Model overview
我们一共有2个model，分别用来预测川普和哈里斯在2024年11月5日美国总统竞选的最终支持率。

\begin{align} 
Score_{Trump} = &\beta_1Pollscore + \beta_2Transparency\_score + \beta_3Duration + \\
        &\beta_4Sample\_size + \beta_5Population + \beta_6Hypothetical + \beta_0 \notag \\[0.5cm]
Score_{Harris} = &\alpha_1Pollscore + \alpha_2Transparency\_score + \alpha_3Duration + \\
        &\alpha_4Sample\_size + \alpha_5Population + \alpha_6Hypothetical + \alpha_0 \notag
\end{align}

Notably, we used Multiple Linear Regression (MLR), which implies the following assumptions:

The core assumption of multiple linear regression is that there is a linear relationship between the dependent variable (outcome) and the independent variables. This linear relationship can be visually checked using scatter plots, which ideally should display a straight-line pattern rather than a curve.
The residuals (the differences between observed and predicted values) should be normally distributed. This assumption can be assessed by examining a Q-Q plot.
The correlation between independent variables should not be too high, meaning multicollinearity should be avoided. This can be checked using the Variance Inflation Factor (VIF).
Homoscedasticity: The variance of the error terms (residuals) should be consistent across all levels of the independent variables. Residuals plotted against predicted values should not display any obvious pattern.
Furthermore, in our model, the variable "duration" is derived from the difference between "start_date" and "end_date" in the original data. This means our model cannot account for the effects brought by time series, but considering the linear relationship between these two, we simplified it to meet the assumptions of using MLR.

Additionally, there are 51 different categories for the "methodology" variable in the original dataset. Having too many categories for a categorical variable would increase the complexity of our model, so we simplified it into four levels. Level 1 represents the lowest reliability of the methodology, while level 4 represents the highest. The specific classifications are as follows:

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-mc
#| tbl-cap: "Methodology classfication"

# Create a summary data frame for the methodologies and their levels
methodology_summary <- data.frame(
  Level = c("level 1", "level 2", "level 3", "level 4"),
  Methodologies = c(
    paste(c("Email", "Email/Online Ad", "Live Phone/Text-to-Web/Email/Mail-to-Web/Mail-to-Phone", "Mail-to-Web/Mail-to-Phone", "Online Ad"), collapse = ", "),
    paste(c("App Panel", "IVR", "IVR/Live Phone/Text/Online Panel/Email", "IVR/Online Panel", "IVR/Online Panel/Email", "IVR/Online Panel/Text-to-Web", "IVR/Online Panel/Text-to-Web/Email", "IVR/Text", "IVR/Text-to-Web", "IVR/Text-to-Web/Email", "Live Phone/Email", "Live Phone/Online Panel/Mail-to-Web", "Live Phone/Text/Online Ad", "Live Phone/Text-to-Web/Email", "Live Phone/Text-to-Web/Email/Mail-to-Web", "Live Phone/Text-to-Web/Online Ad", "Online Panel/Email", "Online Panel/Email/Text-to-Web", "Online Panel/Online Ad", "Text-to-Web/Email", "Text-to-Web/Online Ad"), collapse = ", "),
    paste(c("IVR/Live Phone/Online Panel", "IVR/Live Phone/Online Panel/Text-to-Web", "IVR/Live Phone/Text", "IVR/Live Phone/Text-to-Web", "Live Phone/Online Panel/App Panel", "Live Phone/Online Panel/Text", "Live Phone/Online Panel/Text-to-Web", "Live Phone/Online Panel/Text-to-Web/Text", "Live Phone/Text", "Live Phone/Text/Online Panel", "Live Phone/Text-to-Web", "Live Phone/Text-to-Web/App Panel", "Online Panel", "Online Panel/Text", "Online Panel/Text-to-Web", "Online Panel/Text-to-Web/Text", "Text", "Text-to-Web"), collapse = ", "),
    paste(c("Live Phone", "Live Phone/Online Panel", "Live Phone/Probability Panel", "Online Panel/Probability Panel", "Probability Panel"), collapse = ", ")
  )
)

# Print the summary of methodologies and their levels using kable
kable(methodology_summary, col.names = c("Level", "Methodologies")) %>%
  column_spec(1, width = "1.5cm") %>% # Adjust the width of the first column
  column_spec(2, width = "13cm")
```
The different methodologies were evaluated based on reliability scores ranging from 1 to 10. The scores of 51 combinations were calculated by averaging the individual scores of each methodology in the combination. The results were classified into four levels: high reliability (8.5-10), medium-high reliability (7-8.49), medium reliability (5-6.99), and low reliability (below 5). Methodologies were scored based on several criteria, including statistical rigor, representativeness, response rate, interaction quality, and cost efficiency. High-scoring methodologies, such as those employing strict statistical sampling methods like Probability Panels or those using Live Phone surveys with broad coverage and low refusal rates, received high scores due to their strong representativeness and reliability. Medium-high scoring methodologies included Online Panels, which offer good coverage and low cost but are susceptible to self-selection bias, and Text-to-Web methods, which improve response rates but may have limited representativeness depending on the target demographics. Medium-scoring methodologies, such as App Panels and IVR (Interactive Voice Response), tend to lack broad representativeness or have limitations in interaction quality, making them suitable for niche audiences but not generalizable to a wider population. Low-scoring methodologies, including Email Surveys and methods relying on Online Ads, often suffer from low response rates and significant selection bias, which negatively impact their reliability. These scoring criteria ensure that the methodologies are evaluated in a consistent manner, with higher scores reflecting stronger statistical foundations, broader representativeness, and better data quality.

Additionally, the reason we only compared the data of Trump and Harris to predict which of them would win the election is that, after comparing the weighted competitiveness scores of all candidates, we found that the top three — Trump, Harris, and Biden — had significantly higher scores than the others. As shown in @tbl-t5c, the third-place candidate, Harris, had a weighted competitiveness score of 180714535, which is 5.15 times higher than the fourth-place score of 34987031. Considering that Biden has withdrawn from the race, we ultimately decided to only predict between the most competitive candidates, Trump and Harris. The specific weighting formula is as follows:

\begin{align}
& weighted\_score  = \frac{ {\textstyle \sum_{i  = 1}^{n}score_i} }{n}\times {\textstyle \sum_{i  = 1}^{n}Sample\_Size_i} \\
& \text{Where: }\notag\\
&\hspace{1cm}n\text{ represents the number of polls nominating this candidate.}\notag\\
&\hspace{1cm}Score_i\text{ represents the score obtained by the candidate in the } i^{th}\text{ poll.}\notag\\
&\hspace{1cm}Sample\_Size_i\text{ represents the sample size of the } i^{th}\text{ poll.}\notag
\end{align}

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-wsft5c
#| tbl-cap: "Weighted score for top 5 candidates"
# Define the directory path containing the parquet files
p <- "data/03-cleaned_data"
parquet_files <- list.files(path = here::here(p), full.names = TRUE)

# Initialize an empty dataframe to store the weighted score for each file
weighted_scores <- data.frame(Candidate = character(), Weighted_Score = numeric(), stringsAsFactors = FALSE)

# Iterate over each parquet file
for (file in parquet_files) {
  # Read the parquet file
  df <- read_parquet(here::here(file))
  
  # Calculate the mean of score and sample_size
  score_mean <- mean(df$score, na.rm = TRUE)
  sample_size_mean <- mean(df$sample_size, na.rm = TRUE)
  
  # Calculate the weighted score (multiply by total number of rows)
  weighted_score <- score_mean * sample_size_mean * nrow(df)
  
  # Append the result to the weighted_scores dataframe
  weighted_scores <- rbind(weighted_scores, data.frame(Candidate = sub('_cleaned_data.parquet$', '', basename(file)), Weighted_Score = weighted_score))
}

# Get the top 5 weighted scores
top_5_weighted_scores <- weighted_scores %>% 
  arrange(desc(Weighted_Score)) %>% 
  head(5)

# Print the top 5 weighted scores using kable
top_5_weighted_scores %>% kable()

```











## Model set-up
### response variable
在此章节中，我们用到的数据都是哈里斯和特朗普的训练集。
score是我们模型的response variable，它代表的是某个候选人在某次选票中胜利的可能性，越大代表着该候选人竞选成功的概率越大，通常情况下与该候选人在那次选票中的支持率一样。
下图可以看出来哈里斯和特朗普的score都接近于正态分布。其中川普的score呈现一个对称的趋势，其中最多的score是在50左右。训练集中，川普的score平均数是44.63，方差是24.68。相比之下，哈里斯的score分布有一些偏向于左侧的倾斜。训练集中，哈里斯的score平均数高于特朗普为46.92，方差略低于川普为20.96。值得注意的是川普数据的样本量为3960，而哈里斯只有1636.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-sositd
#| tbl-cap: "Sumarry of score in training datasets"
# Calculate mean, variance, and sample size
summary_stats <- bind_rows(
  train_Trump %>% summarise(mean = round(mean(score, na.rm = TRUE), 2), variance = round(var(score, na.rm = TRUE), 2), sample_size = n()) %>% mutate(dataset = "train_Trump"),
  train_Harris %>% summarise(mean = round(mean(score, na.rm = TRUE), 2), variance = round(var(score, na.rm = TRUE), 2), sample_size = n()) %>% mutate(dataset = "train_Harris")
)

# Display results using kable
summary_stats %>%
  select(dataset, mean, variance, sample_size) %>%
  kable()

```

```{r, fig.pos="H", fig.height=30, fig.width=60}
#| warning: false
#| message: false
#| echo: false
#| label: fig-dositd
#| fig-cap: "Distribution of scores in training dataset"

plots <- list()
# Plot a histogram for the 'pct' variable
plots[["Trump"]]<-ggplot(train_Trump, aes(x = score)) +
  geom_histogram(binwidth = 2, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of pct", x = "pct", y = "Frequency")
plots[["Harris"]]<-ggplot(train_Harris, aes(x = score)) +
  geom_histogram(binwidth = 2, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of pct", x = "pct", y = "Frequency")


### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 2, nrow = 1, heights = unit(rep(20, 20), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)

```


### Predictor
我们的predictors包含以下变量：
```{r}
#| warning: false
#| message: false
#| echo: false
predictors <- c("pollscore","methodology","transparency_score","sample_size","population", 
           "ranked_choice_reallocated", "hypothetical", "duration")
predictors
```

下图展示了在川普的训练集中，numerical predictor 之间的关系。没有明显的趋势代表着它们之间没有明显的correlation。
```{r, fig.width=10, fig.height=10}
#| warning: false
#| message: false
#| echo: false
data2 = train_Trump %>% select("pollscore","transparency_score","sample_size","duration")
pairs( data2 , main = "Predictor vs predictor")
```

关于categorical的：。。。。。。。。。。。。。。。。



### alternative models
最开始我们的模型是

```{r}
#| warning: false
#| message: false
#| echo: false
Trump_model_0 <- lm(
  score ~ numeric_grade + pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Trump)
Harris_model_0 <- lm(
  score ~ numeric_grade + pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Harris)
```

因为我们考虑到numeric_grade和pollscore之间有强线性相关，我们舍弃了这一方案。
```{r, fig.pos="H", fig.height=10, fig.width=10}
#| warning: false
#| message: false
#| echo: false
#| label: fig-rbnap
#| fig-cap: "Relationship between numeric_grade and pollscore"

plots <- list()
# Plot relationship between numeric_grade and pollscore for train_Trump
plots[["Trump"]]<-ggplot(train_Trump, aes(x = numeric_grade, y = pollscore)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Relationship between Numeric Grade and Pollscore (train_Trump)",
       x = "Numeric Grade",
       y = "Pollscore")

# Plot relationship between numeric_grade and pollscore for train_Harris
plots[["Harris"]]<-ggplot(train_Harris, aes(x = numeric_grade, y = pollscore)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Relationship between Numeric Grade and Pollscore (train_Harris)",
       x = "Numeric Grade",
       y = "Pollscore")

### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 1, nrow = 2, heights = unit(rep(4, 10), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)


```



这个是我们的第二个方案。虽然predictors之间没有了相关性，但是methodology，ranked_choice_reallocated，这两个变量并不statistical significant，因为他们的p value都大于0.05.

```{r}
#| warning: false
#| message: false
#| echo: false
Trump_model_1 <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Trump)
Harris_model_1 <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Harris)
```

```{r, fig.height=100,fig.width=100}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-alovitahm
#| tbl-cap: "Significant level of variblaes in the aboanded Harris's model"
# Get the summary of the model
Harris_summary <- summary(Harris_model_1)
# Extract coefficients from the summary
coefficients <- Harris_summary$coefficients
# Extract p-values
Harris_p_values <- coefficients[, 4]
# Create a data frame with the results
Harris_results_table <- data.frame(
  Variable = rownames(coefficients),
  P_Value = format(Harris_p_values, scientific = TRUE)
)
Harris_kable <- kable(Harris_results_table[, 2, drop = FALSE], caption = "Model for Harris", col.names = c("Variable", "P-value"))

Harris_kable

```

```{r, fig.height=100,fig.width=100}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-alovitatm
#| tbl-cap: "Significant level of variblaes in the aboanded Trump's model"

# Get the summary of the model
Trump_summary <- summary(Trump_model_1)
# Extract coefficients from the summary
coefficients <- Trump_summary$coefficients
# Extract p-values
Trump_p_values <- coefficients[, 4]
# Create a data frame with the results
Trump_results_table <- data.frame(
  Variable = rownames(coefficients),
  P_Value = format(Trump_p_values, scientific = TRUE)
)
Trump_kable <- kable(Trump_results_table[, 2, drop = FALSE], caption = "Model for Trump", col.names = c("Variable", "P-value"))

Trump_kable
```





因此，我们有有了最后的模型。




## validation
从您的结果来看，所有变量的 GVIF 值都在 1 到 1.3 之间，这些数值非常低，表明各个自变量之间的共线性很小，模型并没有因为共线性而受到显著影响。
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-vohfm
#| tbl-cap: "VIF of Harris's final model"
# Add a column for variable names (convert row names to a column)

harris_vif <- vif(Harris_model)

# 将 VIF 结果转换为数据框
# 如果是 GVIF（针对多分类变量），则处理为数据框

harris_vif_df <- as.data.frame(harris_vif)



harris_vif_df$Variable <- rownames(harris_vif_df)

# Rearrange columns so that the variable name column is the first column

harris_vif_df <- harris_vif_df[, c(ncol(harris_vif_df), 1:(ncol(harris_vif_df)-1))]

# Use kable to create a formatted table from VIF results

kable(harris_vif_df[, 2, drop = FALSE], format = "html", caption = "VIF for Harris Model")



```

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-votfm
#| tbl-cap: "VIF of Trump's final model"

trump_vif <- vif(Trump_model)


# 将 VIF 结果转换为数据框
# 如果是 GVIF（针对多分类变量），则处理为数据框
trump_vif_df <- as.data.frame(trump_vif)

# Add a column for variable names (convert row names to a column)
trump_vif_df$Variable <- rownames(trump_vif_df)


# Rearrange columns so that the variable name column is the first column
trump_vif_df <- trump_vif_df[, c(ncol(trump_vif_df), 1:(ncol(trump_vif_df)-1))]

# Use kable to create a formatted table from VIF results

kable(harris_vif_df[, 2, drop = FALSE], format = "html", caption = "VIF for Harris Model")

```








```{r}
#| warning: false
#| message: false
#| echo: false
par(mfrow=c(2,2))
plot(Harris_model,1)
plot(Harris_model,2)
```

```{r}

par(mfrow=c(2,2))
plot(Trump_model,1)
plot(Trump_model,2)
```
然后就是描述一下response variable是normal的，然后numerical variable没有显著关系（这些在打他部分有讲过）
总结，满足了MLR的条件，说明我们的好
```{r,message=FALSE, echo=FALSE,warning=FALSE,fig.height = 10, fig.width=10}
# Generate predictions using the model
plots <- list()
predictions <- predict(Harris_model, newdata = test_Harris)

actual <- test_Harris$score

results_df <- data.frame(Actual = actual, Predicted = predictions)

# Plot the predicted values vs actual values
plots[["Harris"]]<-ggplot(results_df, aes(x = predictions, y = actual)) +
  geom_point(color = "blue") + # Scatter plot of predicted vs actual values
  labs(x = "Predicted Values", y = "Actual Values", title = "Comparison of Predicted and Actual Values") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") + # Add reference line y = x
  theme_minimal() # Use minimal theme for the plot


# Generate predictions using the model
predictions_1 <- predict(Trump_model, newdata = test_Trump)

actual_1 <- test_Trump$score

results_df_1 <- data.frame(Actual = actual_1, Predicted = predictions_1)

# Plot the predicted values vs actual values
plots[["Trump"]] <-ggplot(results_df_1, aes(x = predictions_1, y = actual_1)) +
  geom_point(color = "blue") + # Scatter plot of predicted vs actual values
  labs(x = "Predicted Values", y = "Actual Values", title = "Comparison of Predicted and Actual Values") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") + # Add reference line y = x
  theme_minimal() # Use minimal theme for the plot

### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 1, nrow = 2, heights = unit(rep(4, 8), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)


```

# Result
## featured values used in prediction

In our analysis, we designated specific poll-related features as "featured values" to serve as representative indicators within each candidate's dataset. These featured values were chosen to highlight the most impactful aspects of the polling data that consistently influenced the support scores for Donald Trump and Kamala Harris. By selecting these representative values, we aimed to streamline the analysis and focus on the factors that most strongly characterized each candidate’s data.

We selected representative feature values for each candidate's dataset by processing each variable based on its type. For numeric variables (e.g., numeric_grade, pollscore, transparency_score, duration, sample_size), we determined whether to use the mean or median by evaluating skewness; variables with low skewness used the mean, while more skewed variables used the median to represent typical values. Categorical variables (e.g., methodology, population) were represented by the most frequent category, while Boolean variables (e.g., ranked_choice_reallocated, hypothetical) were set to TRUE or FALSE based on the most common value. This approach allowed us to capture the key characteristics of each candidate's data in a summarized form.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-dffp
#| tbl-cap: "Datas for final prediction"

select_feature_value <- function(data, candidate_name) {
  feature_values <- list()
  for (col_name in names(data)) {
    col_data <- data[[col_name]]
    # Numeric variables: Choose mean or median based on skewness
    if (is.numeric(col_data)) {
      # Check if there are enough valid values to compute skewness
      if (sum(!is.na(col_data)) > 1) {  # Ensure there is more than one valid value
        skew_val <- skewness(col_data, na.rm = TRUE)
        if (!is.na(skew_val) && skew_val < 1) {
          feature_values[[col_name]] <- round(mean(col_data, na.rm = TRUE),2)
        } else {
          feature_values[[col_name]] <- round(median(col_data, na.rm = TRUE),2)
        }
      } else {
        # Default to median if skewness cannot be computed
        feature_values[[col_name]] <- median(col_data, na.rm = TRUE)
      }
    }
    
    # Categorical variables: Choose mode (most frequent value)
    else if (is.character(col_data)) {
      feature_values[[col_name]] <- Mode(col_data)
    }
    
    # Boolean variables: Choose TRUE or FALSE based on which one appears more frequently
    else if (is.logical(col_data)) {
      true_count <- sum(col_data, na.rm = TRUE)
      false_count <- sum(!col_data, na.rm = TRUE)
      feature_values[[col_name]] <- if (true_count >= false_count) TRUE else FALSE
    }
  }
  # Add the candidate name to the results
  feature_values[["Candidate"]] <- candidate_name
  return(feature_values)
}

# Define a function to calculate the mode (most frequent value)
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Calculate feature values for each candidate
trump_features <- select_feature_value(full_Trump, "Donald Trump")
harris_features <- select_feature_value(full_Harris, "Kamala Harris")

all_candidate_features <- data_frame(trump = trump_features, harris = harris_features)

# Round numeric columns to two decimal places before pivoting
all_candidate_features <- all_candidate_features %>%
  mutate(across(everything(), as.character))  # Convert all columns to character for compatibility in pivot_longer

all_candidate_features <- head(all_candidate_features, -1)

variables <- c("numeric_grade", "pollscore", "methodology", "transparency_score", 
               "sample_size", "population", "ranked_choice_reallocated", 
               "hypothetical", "score", "duration")

all_candidate_features$variables <- variables

all_candidate_features <- all_candidate_features[, c("variables", setdiff(names(all_candidate_features), "variables"))]


# Display the final table with kable
kable(all_candidate_features)

```
## Prediction result of the linear model

Using the selected feature values for each candidate, we applied our trained predictive models to estimate the support levels for Kamala Harris and Donald Trump. The bar plot above illustrates the predicted values derived from our analysis. According to the model, Kamala Harris has a predicted support value of approximately 47.65, while Donald Trump is predicted to receive a support value of around 43.51. These predictions suggest an advantage for Kamala Harris over Donald Trump in terms of expected support within the context of the data used.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
Harris_predict <- round(predict(Harris_model, newdata = harris_features),2)
Trump_predict <- round(predict(Trump_model, newdata = trump_features),2)

# Store predictions in a data frame
predictions <- data.frame(
  Candidate = c("Kamala Harris", "Donald Trump"),
  Prediction = c(Harris_predict, Trump_predict)
)

# Create the bar plot
ggplot(predictions, aes(x = Candidate, y = Prediction, fill = Candidate)) +
  geom_bar(stat = "identity", width = 0.5) +
  labs(title = "Predicted Values for Each Candidate",
       x = "Candidate",
       y = "Prediction") +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_text(aes(label = Prediction), vjust = -0.3)
```
## Conclusion

Overall, our approach demonstrates how feature engineering and predictive modeling can offer insights into candidate support based on the available data. However, it is important to interpret these results cautiously, as they rely on specific variables and assumptions embedded within the dataset. In this analysis, we aggregated representative feature values for each candidate by using the mean or median for numeric variables, the mode for categorical variables, and the most frequent occurrence for Boolean values. Further refinement and additional data could enhance the robustness of these predictions, contributing to a more comprehensive forecast in future studies.

# Discussion

This paper presents a predictive analysis of voter support for 2024 U.S. presidential candidates Kamala Harris and Donald Trump. Using a “poll-of-polls” approach, it integrates polling data from diverse sources, emphasizing reliability, sample size, and methodology. Linear and Bayesian models were applied to improve prediction accuracy.

The analysis provides two key insights. First, our model predicts a slight advantage for Kamala Harris, with a support estimate of 47.6% compared to Donald Trump’s 43.5%, indicating a competitive but narrow lead. Second, it underscores the impact of poll reliability on predictive accuracy. Traditional methods like live phone surveys show greater accuracy than online methods, reinforcing the importance of reliability-weighted data in improving forecast precision.

This analysis is limited by its use of static variables, which may not capture shifts in public opinion. For instance, major events like debates can influence voter sentiment, yet the model lacks real-time responsiveness. Additionally, aggregating data from different poll methodologies may introduce bias; for example, online panels may skew younger while live phone surveys often favor older demographics. Future work could include real-time data and refined weighting to enhance adaptability and consistency.

Future research could incorporate time series analysis to track evolving voter sentiment and add demographic or economic factors for greater precision. Integrating social media sentiment and machine learning could provide deeper insights into regional voting patterns.

# Appendix

## Analysis of YouGov Pollster Methodology

In this appendix, we provide a deep-dive analysis of the methodology employed by YouGov, one of the pollsters included in our sample. YouGov is an international online research data and analytics technology group. It is a leading platform for online survey, which has a continuously growing dataset of over 27 million registered members. This pollster has a 3.0 grade according to FiveThirtyEight, which is the highest score. This analysis covers key aspects of YouGov's survey methodology, highlighting its strengths, weaknesses, and the unique features of its approach.

### Population, Frame, and Sample

YouGov utilizes an online panel to collect survey responses, with participants drawn from a broad population base, which typically comprises all U.S. adults citizens. Respondents are chosen based on a non-probability sampling, which means not everyone in the population has an equal chance of being selected. However, the sample is adjusted using statistical weighting to better represent the target population. The sampling frame consists of individuals who have signed up to participate in surveys, representing a range of demographic characteristics. However, as an online panel, there may be limitations regarding coverage bias, particularly for individuals with limited internet access.

### Sample Recruitment

YouGov recruits participants through online advertisements and other digital marketing techniques,  with surveys offers surveys in multiple languages. The recruitment process is designed to ensure that the panel is as representative as possible. For instance, YouGov collects information such as email addresses and IP addresses when new members join the panel. Additionally, YouGov monitors survey completion time and answer consistency to ensure the data is accurate. Respondents who fail quality checks are removed.

### Sampling Approach and Trade-offs

YouGov employs a form of quota sampling combined with weighting adjustments to make the sample representative of the target population. To ensure representativeness, YouGov selects respondents based on key demographic characteristics such as age, gender, race, education, and voting behavior. These characteristics are used to set quotas, and the sample is adjusted with statistical weighting to align with the distribution of these characteristics in the target population. For example, if a particular demographic group is underrepresented in the sample, their responses are given greater weight to correct the imbalance. One trade-off of this method is that, although it helps improve representativeness, it may not fully eliminate selection bias due to the reliance on an online panel, which can lead to overrepresentation or underrepresentation of certain groups. Additionally, the process of weighting adjustments may introduce additional errors if the weights are inaccurate or if certain groups are given disproportionately high weights, leading to increased variability and potential bias in the final results.

### Handling Non-response

Non-response is managed by using statistical weighting to adjust the sample to more closely reflect the demographic makeup of the target population. While this helps mitigate some of the biases associated with non-response, it cannot fully account for differences between respondents and non-respondents, especially when non-response is correlated with key survey variables.

### Strengths and Weaknesses of the Questionnaire

The YouGov questionnaire is well-designed to capture a wide range of attitudes and behaviors. The use of standardized questions ensures consistency across surveys, allowing for longitudinal analysis. However, as an online survey, there is the risk of respondents providing socially desirable answers or rushing through the survey without providing thoughtful responses. Additionally, the format may limit the depth of responses compared to in-person interviews.

Overall, YouGov's methodology provides a cost-effective and timely approach to data collection, particularly useful for understanding trends across large populations. However, the use of an online panel introduces certain limitations that must be acknowledged when interpreting the results.

## Ideal Methodology and Survey for Predicting the U.S. Presidential Election

### Budget Overview
With a budget of $100,000, the goal is to design an efficient and representative method for predicting the U.S. presidential election. This methodology will include sampling strategies, respondent recruitment, data validation, poll aggregation, and survey implementation details.

### Sampling Methodology
A stratified sampling approach will be used to ensure diversity and representation. The population will be divided into relevant strata such as age, gender, geographic region, race, and political affiliation. This approach ensures that each subgroup is adequately represented, thereby reducing sampling bias.

### Respondent Recruitment
Respondents will be recruited through online panels. Partnerships with established survey platforms and third-party providers will help reach a broad and representative group of participants, such as through platforms like Instagram, YouTube, and various news websites. Small monetary compensation or gift cards will be offered as incentives to encourage participation. Additional incentives will be provided to underrepresented groups, such as individuals with lower educational attainment or residents of rural areas, to ensure more inclusive recruitment. The aim is for a sample size of approximately 10,000 respondents, which would achieve a margin of error of ±1% at a 95% confidence level.

### Data Validation
Data validation will involve cross-referencing respondent demographic information with census data to confirm representativeness. Additionally, responses will be reviewed for accuracy, and suspicious or incomplete answers will be flagged for further inspection. Responses completed too quickly or that include repeated answers such as "prefer not to say" or "other" will be discarded. IP addresses will be tracked to prevent duplicate submissions.

### Poll Aggregation and Methodology Features
Once all responses are collected, weights will be applied according to electoral demographics and voter turnout to ensure the sample represents the U.S. population. Poll aggregation will also involve adjustments for known biases, such as overreporting in certain demographic groups or historical voting trends. Bayesian updating will be used to refine predictions continuously as more data becomes available.

### Survey Implementation
The survey will be implemented using Google Forms, which allows for easy distribution and data collection. The survey will include questions related to voter preferences, key issues, and demographic information. Questions will be designed to minimize leading language and provide a range of response options to avoid bias. Keeping the survey brief (approximately 5 minutes with 12 questions) will help maintain respondent focus.

### Budget Allocation
- $60K for Recruitment Costs and Survey Platform Fees, including advertising
- $10K for respondent incentives
- $20K for data processing, weighting, and modeling
- $10K for data security and administrative costs

### Survey Link and Copy
The Google Forms survey link will be included here: https://docs.google.com/forms/d/e/1FAIpQLSdcd_neJf83lJMZGzmcUcPkDd-R1vPk98gPIDsD4KC_X6T8tQ/viewform. 

The survey questions are listed below: 
1. **What is your age group?** 
   - 18-24
   - 25-34
   - 35-44
   - 45-54
   - 55+

2. **What is your gender?**
   - Male
   - Female
   - Non-binary
   - Prefer not to say

3. **What is your ethnicity?**
   - White
   - Black or African American
   - Asian
   - Hispanic or Latino
   - Native American or Alaska Native
   - Two or more races
   - Other
   - Prefer not to say

4. **In which state do you currently reside?** *(Open-ended response)*

5. **What is your highest level of education completed?**
   - High school
   - Associate degree
   - Bachelor's degree
   - Other/Prefer not to say

6. **What is your political affiliation?**
   - Democrat
   - Republican
   - Independent
   - Other/Prefer not to say

7. **How likely are you to vote in the upcoming presidential election?** *(Scale of 1-5)*

8. **Which candidate do you currently support for president?**
   - Kamala Harris
   - Donald Trump
   - Other

9. **What is the most important issue to you in the upcoming election?**
   - Economy
   - Healthcare
   - Education
   - Climate change
   - Other/Prefer not to say

10. **What do you consider your economic status?**
    - Lower class
    - Lower-middle class
    - Middle class
    - Upper-middle class
    - Upper class
    - Prefer not to say

11. **How would you describe your household's financial situation compared to last year?**
    - Better
    - Worse
    - About the same
    - Prefer not to say

12. **How satisfied are you with the current administration's handling of key issues?** *(Scale of 1-5)*

## Raw data full descriptions

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: fig-rdd
#| fig-cap: "Raw Data Distribution"


# Define variable groups
set1_vars <- c("pollster_rating_id", "pollster_id", "sponsor_candidate_id", "sponsor_candidate_party")
set2_vars <- c("tracking", "internal", "partisan")
set3_vars <- c("sponsor_ids", "question_id", "internal", "race_id")

# Define a function to generate a grid of plots for a given set of variables with increased text size
plot_variable_distributions <- function(data, vars) {
  plots <- list()
  for (var in vars) {
    if (is.numeric(data[[var]])) {
      p <- ggplot(data, aes(x = .data[[var]])) +
        geom_histogram(bins = 30, fill = "steelblue", color = "black") +
        labs(title = var) +
        theme_minimal() +
        theme(
          plot.title = element_text(size = 18, face = "bold"),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank()
        )
    } else {
      p <- ggplot(data, aes(x = .data[[var]])) +
        geom_bar(fill = "steelblue", color = "black") +
        labs(title = var) +
        theme_minimal() +
        theme(
          plot.title = element_text(size = 18, face = "bold"),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.y = element_blank(),
          axis.text.x = element_text(size = 14, angle = 45, hjust = 1)
        )
    }
    plots[[var]] <- p
  }
  return(plots)
}

# Generate plots for each set of variables
plot1 <- plot_variable_distributions(raw_data, set1_vars)
plot2 <- plot_variable_distributions(raw_data, set2_vars)
plot3 <- plot_variable_distributions(raw_data, set3_vars)

# Arrange the first three sets of plots into grids and display them
grid.arrange(grobs = plot1, ncol = 2, top = textGrob("Distribution of Variables (Set 1)", gp=gpar(fontsize=20, fontface="bold")))
grid.arrange(grobs = plot2, ncol = 2, top = textGrob("Distribution of Variables (Set 2)", gp=gpar(fontsize=20, fontface="bold")))
grid.arrange(grobs = plot3, ncol = 2, top = textGrob("Distribution of Variables (Set 3)", gp=gpar(fontsize=20, fontface="bold")))

# Separate set4, set5, and set6 variables for individual adjustments

# Set 4: State Plot (excluding NA)
state_plot <- raw_data %>%
  filter(!is.na(state)) %>%  
  count(state, sort = TRUE) %>%
  top_n(10) %>%
  ggplot(aes(y = reorder(state, n), x = n)) +
  geom_bar(stat = "identity", fill = "steelblue", color = "black") +
  labs(title = "Distribution of State (Set 4)") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 20, face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12)
  )

# Set 5: ranked_choice_round_plot Plot (excluding NA)
ranked_choice_round_plot <- raw_data %>%
  filter(!is.na(ranked_choice_round)) %>%  
  ggplot(aes(x = ranked_choice_round)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  labs(title = "Distribution of ranked_choice_round (Set 5)") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 20, face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_text(size = 12, angle = 45, hjust = 1),
    axis.text.y = element_text(size = 12)
  )

created_at_plot <- raw_data %>%
  filter(!is.na(created_at)) %>%  # 去掉NA值
  ggplot(aes(x = as.POSIXct(created_at, format = '%m/%d/%y %H:%M'))) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  labs(title = "Distribution of Created At (Set 8)") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 20, face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.x = element_text(size = 12, angle = 45, hjust = 1),
    axis.text.y = element_text(size = 12)
  )

# Display each plot individually
print(state_plot)
print(ranked_choice_round_plot)
print(created_at_plot)
```




