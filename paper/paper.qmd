---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---
```{r}
#| include: false
#| warning: false
#| message: false
#| echo: false
#### Workspace setup ####
library(tidyverse)
library(knitr)
library(dplyr)
library(arrow)
library(patchwork)
library(car)
library(kableExtra)
library(gridExtra)
library(moments)
set.seed(912)
#### Read data ####
raw_data <- read_csv(here::here("data/01-raw_data/raw_data.csv"))
train_Trump <- read_parquet(here::here("data/02-analysis_data/01-training/train_Trump.parquet"))
train_Harris <- read_parquet(here::here("data/02-analysis_data/01-training/train_Harris.parquet"))
test_Trump <- read_parquet(here::here("data/02-analysis_data/02-testing/test_Trump.parquet"))
test_Harris <- read_parquet(here::here("data/02-analysis_data/02-testing/test_Harris.parquet"))
full_Trump <- read_parquet(here::here("data/02-analysis_data/00-full/full_Trump.parquet"))
full_Harris <- read_parquet(here::here("data/02-analysis_data/00-full/full_Harris.parquet"))
Trump_model <- readRDS(here::here("models/Trump_model.rds"))
Harris_model <- readRDS(here::here("models/Harris_model.rds"))
```

# Introduction

# Data {#sec-data}

## Overview

## Raw data
Raw data 一共包含了52个variable以及17133个sample.
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-vord
#| tbl-cap: "Varibales of raw data"

# Get the column names and arrange them into multiple columns
column_names <- names(raw_data)
num_columns <- 3  # Set the desired number of columns
num_rows <- ceiling(length(column_names) / num_columns)
matrix_data <- matrix(c(column_names, rep("", num_columns * num_rows - length(column_names))), 
                      nrow = num_rows, byrow = TRUE)

# Convert the matrix to a data frame and format it with kable, set font size, and adjust header styling to remove extra row
kable(as.data.frame(matrix_data), 
      col.names = NULL)
```
其中重要的variables，其余的在appdendix
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-ivatd
#| tbl-cap: "Important variables and their descriptions"

variable_descriptions <- data.frame(
  Variable = c("poll_id", "methodology", "population", "ranked_choice_reallocated",
               "hypothetical", "answer", "numeric_grade", "pollscore", 
               "transparency_score", "start_date", "end_date", "sample_size", "pct"),
  Description = c(
    "Unique identifier for each poll conducted.",
    "The method used to conduct the poll (e.g., Online Panel).",
    "The abbreviated description of the respondent group, typically indicating their voting status (e.g., 'lv' for likely voters).",
    "Indicates if ranked-choice voting reallocations have been applied in the results.",
    "Indicates whether the poll is about a hypothetical match-up.",
    "The response or answer choice given in the poll (e.g., the candidate's party).",
    "A numeric rating given to the pollster to indicate their quality or reliability (e.g., 3.0).",
    "A numeric value representing the score or reliability of the pollster in question (e.g., -1.1).",
    "A score reflecting the pollster's transparency about their methodology (e.g., 9.0).",
    "The date the poll began (e.g., 10/8/24).",
    "The date the poll ended (e.g., 10/11/24).",
    "The total number of respondents participating in the poll (e.g., 2712).",
    "The percentage of the vote or support that the candidate received in the poll (e.g., 51.0 for Kamala Harris)."
  )
)

# Create the table using kable
kable(variable_descriptions) %>%
  kable_styling() %>%
  column_spec(1, width = "4.5cm") %>% # Adjust the width of the first column
  column_spec(2, width = "10cm")    # Adjust the width of the second column
```
52个varibles中以下几个与我们的project明显无关，我们在此不做讨论：
"notes", "url", "url_article", "url_topline", "url_crosstab", "source"
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
del_1 <- c("notes", "url", "url_article", "url_topline", "url_crosstab", "source")
droped_data <- raw_data %>% select(-any_of(del_1))
```
此外，还有一些相同的variables，我们保留其一，剩下的也不做讨论，它们包括："pollster", "sponsors", "display_name", "pollster_rating_name", "sponsor_candidate", "endorsed_candidate_name", "population_full", "candidate_id", "candidate_name"
```{r}
#| warning: false
#| message: false
#| echo: false
# 这里需要画一个table，展示删除的重复变量
del_2 <- c("pollster", "sponsors", "display_name", "pollster_rating_name", "sponsor_candidate", "endorsed_candidate_name",
           "population_full", "candidate_id", "candidate_name")
droped_data <- droped_data %>% select(-any_of(del_2))
```
常数变量我们也不做讨论，因为无法影响我们的预测，它们是：
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-cv
#| tbl-cap: "Constant variables"
# Identify variables where all values are the same (including NA)
same_value_variables <- names(droped_data)[sapply(droped_data, function(x) length(unique(x)) == 1)]
# Create a data frame with variables and their unique values
same_value_data <- data.frame(Variable = same_value_variables, Value = sapply(same_value_variables, function(var)
unique(na.omit(droped_data[[var]]))[1]))
# Print the names of variables with all identical values using kable
kable(same_value_data[, 2, drop = FALSE], col.names = c("Variable", "Value"))
del_4 <- c("endorsed_candidate_id", "endorsed_candidate_party", "subpopulation", "cycle", "election_date", "stage", "nationwide_batch", 
           "office_type", "seat_number", "seat_name")
droped_data <- droped_data %>% select(-any_of(del_4))
```
其中categorical的有"poll_id", "pollster_id", "sponsor_ids", "pollster_rating_id", "methodology", "state",
         "sponsor_candidate_id", "sponsor_candidate_party", "question_id", "population", "tracking", "created_at", "internal",
         "partisan","race_id", "ranked_choice_reallocated", "ranked_choice_round", "hypothetical","party","answer"
```{r}
#| warning: false
#| message: false
#| echo: false
catego <- c("poll_id", "pollster_id", "sponsor_ids", "pollster_rating_id", "methodology", "state",
         "sponsor_candidate_id", "sponsor_candidate_party", "question_id", "population", "tracking", "created_at", "internal",
         "partisan","race_id", "ranked_choice_reallocated", "ranked_choice_round", "hypothetical","party","answer")
```
重要的categorical为下面的，剩下的将在appendix阐述："poll_id", "methodology", "population", "ranked_choice_reallocated", "hypothetical","answer"
```{r}
#| warning: false
#| message: false
#| echo: false
catego_inp <- c("poll_id", "methodology", "population", "ranked_choice_reallocated", "hypothetical","answer")
```
一共有3530个poll
```{r}
#| warning: false
#| message: false
#| echo: false
# Get unique Poll IDs and print the count
unique_poll_ids <- unique(raw_data$poll_id)
```
描述
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: fig-bv
#| fig-cap: "Boolean variables"
plots <- list()
# Create bar charts for 'ranked_choice_reallocated' and 'hypothetical'
plots[["ranked_choice"]] <- ggplot(raw_data, aes(x = ranked_choice_reallocated)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Ranked Choice Reallocated", x = "Ranked Choice Reallocated", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )

plots[["hypothetical"]] <- ggplot(raw_data, aes(x = hypothetical)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Hypothetical", x = "Hypothetical", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )

# Combine and print the plots using patchwork
combined_plot <- wrap_plots(plots, ncol = 2, nrow = 1, heights = unit(rep(3, 4), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)

```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-cv
#| fig-cap: "Catogorical variables"

plots <- list()
# Find the top 3 most frequent values in 'methodology' and group others as 'Other'
methodology_counts <- sort(table(raw_data$methodology), decreasing = TRUE)
top_3_methodologies <- names(methodology_counts)[1:3]
raw_data$methodology_grouped <- ifelse(raw_data$methodology %in% top_3_methodologies, raw_data$methodology, "Other")
# Create a bar chart for the grouped 'methodology'
plots[["methodology"]] <- ggplot(raw_data, aes(x = methodology_grouped)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Top 3 Methodologies and Others", x = "Methodology", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )
plots[["population"]] <- ggplot(raw_data, aes(x = population)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Population", x = "Population", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )
# Find the top 3 most frequent values in 'answer' and group others as 'Other'
answer_counts <- sort(table(raw_data$answer), decreasing = TRUE)
top_3_answer <- names(answer_counts)[1:3]
raw_data$answer <- ifelse(raw_data$answer %in% top_3_answer, raw_data$answer, "Other")
# Create a bar chart for the grouped 'answer'
plots[["answer"]] <- ggplot(raw_data, aes(x = answer)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Top 3 answer and Others", x = "answer", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )
combined_plot <- wrap_plots(plots, ncol = 3, nrow = 1, heights = unit(rep(8, 4), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)
```
以及numerical的variables："numeric_grade"      "pollscore"          "transparency_score" "start_date"         "end_date"        "sample_size" "pct"
```{r}
#| warning: false
#| message: false
#| echo: false
numer <- droped_data %>% select(-any_of(catego))
```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-donvp1
#| fig-cap: "Distribution of numerical varibales part 1"
### Create Plots for Numeric Variables ###
# Create a list to store plots
plots <- list()
# Loop through selected numeric variables and plot their distributions
for (variable in names(numer %>% select(numeric_grade, pollscore, transparency_score))) {
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(binwidth = 0.5, fill = "#69b3a2", color = "black", alpha = 0.8) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
    theme_minimal(base_size = 30) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 10),
      axis.text = element_text(size = 10)
    )
}
### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 3, nrow = 1, heights = unit(rep(8, 4), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)
```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-donvp2
#| fig-cap: "Distribution of numerical varibales part 2"
### Create Plots for Numeric Variables ###
# Create a list to store plots
plots <- list()
# Loop through selected numeric variables and plot their distributions
for (variable in names(numer %>% select(sample_size, pct))) {
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(binwidth = 5, fill = "#69b3a2", color = "black", alpha = 0.8) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
    theme_minimal(base_size = 30) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 10),
      axis.text = element_text(size = 10)
    )
}
### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 2, nrow = 1, heights = unit(rep(8, 8), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)
```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-dodv
#| fig-cap: "Distribution of date varibales"

### Define Variables and Prepare Data ###
# Convert start_date and end_date to Date type
raw_data$start_date <- ymd(raw_data$start_date)
raw_data$end_date <- ymd(raw_data$end_date)
# Define the date variables to plot
date_variables <- c("start_date", "end_date")
### Create Plots for Date Variables ###
# Loop through selected date variables and plot their distributions
plots <- list()
for (variable in names(numer %>% select(start_date, end_date))) {
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(binwidth = 80, fill = "#69b3a2", color = "black", alpha = 0.8) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
        theme_minimal(base_size = 30) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 10),
      axis.text = element_text(size = 10)
    )
}
### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 2, nrow = 1, heights = unit(rep(8, 4), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)

```
## Cleaned data
In the raw data, we initially identified a total of 52 variables. Some of these variables, such as 'url', are clearly unrelated to the objectives of this project. There are also constant variables, such as 'election_date', which consistently contains the value '11/5/24'. Additionally, we found duplicate variables conveying the same information, like 'pollster_id' and 'pollster'. Therefore, we first removed these irrelevant and redundant variables. The remaining variables are as follows:
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-rv
#| tbl-cap: "Remained variables"

# Get the column names and arrange them into multiple columns
column_names <- names(droped_data)
num_columns <- 3  # Set the desired number of columns
num_rows <- ceiling(length(column_names) / num_columns)
matrix_data <- matrix(c(column_names, rep("", num_columns * num_rows - length(column_names))), 
                      nrow = num_rows, byrow = TRUE)

# Convert the matrix to a data frame and format it with kable, set font size, and adjust header styling to remove extra row
kable(as.data.frame(matrix_data), 
      col.names = NULL)
```
Next, we calculated the percentage of missing values for each variable across the entire dataset. We then removed all variables with more than 40% missing values. These variables, along with their respective proportions of missing values, are as follows:
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-vwbpomv
#| tbl-cap: "Variables with big porpotion of missing values"
na_proportions <- sapply(names(droped_data), function(var) {
  round(mean(is.na(raw_data[[var]])), 2)
})

# Create a data frame with variable names and their NA proportions
na_proportions_data <- data.frame(Variable = names(droped_data), NA_Proportion = na_proportions)

# Filter variables with NA proportion greater than 40%
high_na_proportions <- na_proportions_data[na_proportions_data$NA_Proportion > 0.4, ]

# Print the NA proportions greater than 40% using kable
kable(high_na_proportions[, 2, drop = FALSE], col.names = c("Variable", "NA Proportion"))

del_5 <- c("sponsor_ids", "state", "sponsor_candidate_id", "sponsor_candidate_party", "tracking",
           "internal","partisan","ranked_choice_round")
droped_data <- droped_data %>% select(-any_of(del_5))

```
Since the influence of pollsters can be quantified using their ratings, such as 'numeric_grade', 'pollscore', and 'transparency_score', we removed these variables to simplify the dataset and the model. Similarly, 'created_at' was also removed due to its strong correlation with 'start_date'. 
```{r}
#| warning: false
#| message: false
#| echo: false
del_6 <- c("pollster_id", "pollster_rating_id", "created_at")
droped_data <- droped_data %>% select(-any_of(del_6))
```
Finally, due to the limitations of our model, we removed 'race_id', 'party', and 'question_id'. The reason for this is that we will extract and analyze the data for each candidate individually, which makes 'race_id' and 'party' constant within the corresponding dataset. Additionally, 'question_id' contains 6,421 unique values, making it unsuitable for categorization, and we removed it to avoid overfitting the model.
```{r}
#| warning: false
#| message: false
#| echo: false
# Get unique Question IDs and print the count
unique_question_ids <- unique(raw_data$question_id)
```
Finally, the remaining variables are as follows:
```{r, fig.height=30, fig.width=30}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-fv
#| tbl-cap: "Final variables"
final <- c("poll_id","numeric_grade","pollscore","methodology","transparency_score","sample_size","population", 
           "ranked_choice_reallocated", "hypothetical", "answer","pct","start_date", "end_date")

# Get the column names and arrange them into multiple columns
column_names <- final
num_columns <- 3  # Set the desired number of columns
num_rows <- ceiling(length(column_names) / num_columns)
matrix_data <- matrix(c(column_names, rep("", num_columns * num_rows - length(column_names))), 
                      nrow = num_rows, byrow = TRUE)

# Convert the matrix to a data frame and format it with kable, set font size, and adjust header styling to remove extra row
kable(as.data.frame(matrix_data), 
      col.names = NULL)
```
After finalizing the variables, we first created a new variable named 'duration', which replaced 'start_date' and 'end_date'. This new variable represents the number of days between 'start_date' and 'end_date'.Next, we categorized the 51 different methodologies into four levels, ranging from the least reliable and accurate (level_1) to the most reliable (level_4). 

Subsequently, we handled the missing values by imputing numerical variables with their mean values and categorical variables with their mode. Since our results are not exact percentages, we used 'score' to name what would typically be called 'pct'. We then finalize and tidy up the variable names.

Next, we extracted the data for each candidate individually. We calculated a weighted score by weighting according to the number of times each candidate was mentioned in the polls. After comparison, we observed that the top three candidates—Trump, Harris, and Biden—had significantly higher scores than the remaining candidates. Given that Biden has withdrawn from the race, we are now focusing only on the datasets for Trump and Harris for further analysis. 

Next, we split the data for Trump and Harris into a training set (70%) and a test set (30%). These four datasets form our analysis data. Below is a portion of the Trump training set for reference:
```{r}
#| warning: false
#| message: false
#| echo: false
kable(head(train_Trump), col.names = names(train_Trump))
```
## Measurement

## Similar dataset

# Model

## Model overview
我们一共有2个model，分别用来预测川普和哈里斯在2024年11月5日美国总统竞选的最终支持率。

\begin{align} 
Score_{Trump} = &\beta_1Pollscore + \beta_2Transparency\_score + \beta_3Duration + \\
        &\beta_4Sample\_size + \beta_5Population + \beta_6Hypothetical + \beta_0 \notag \\[0.5cm]
Score_{Harris} = &\alpha_1Pollscore + \alpha_2Transparency\_score + \alpha_3Duration + \\
        &\alpha_4Sample\_size + \alpha_5Population + \alpha_6Hypothetical + \alpha_0 \notag
\end{align}

Notably, we used Multiple Linear Regression (MLR), which implies the following assumptions:

The core assumption of multiple linear regression is that there is a linear relationship between the dependent variable (outcome) and the independent variables. This linear relationship can be visually checked using scatter plots, which ideally should display a straight-line pattern rather than a curve.
The residuals (the differences between observed and predicted values) should be normally distributed. This assumption can be assessed by examining a Q-Q plot.
The correlation between independent variables should not be too high, meaning multicollinearity should be avoided. This can be checked using the Variance Inflation Factor (VIF).
Homoscedasticity: The variance of the error terms (residuals) should be consistent across all levels of the independent variables. Residuals plotted against predicted values should not display any obvious pattern.
Furthermore, in our model, the variable "duration" is derived from the difference between "start_date" and "end_date" in the original data. This means our model cannot account for the effects brought by time series, but considering the linear relationship between these two, we simplified it to meet the assumptions of using MLR.

Additionally, there are 51 different categories for the "methodology" variable in the original dataset. Having too many categories for a categorical variable would increase the complexity of our model, so we simplified it into four levels. Level 1 represents the lowest reliability of the methodology, while level 4 represents the highest. The specific classifications are as follows:

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-mc
#| tbl-cap: "Methodology classfication"

# Create a summary data frame for the methodologies and their levels
methodology_summary <- data.frame(
  Level = c("level 1", "level 2", "level 3", "level 4"),
  Methodologies = c(
    paste(c("Email", "Email/Online Ad", "Live Phone/Text-to-Web/Email/Mail-to-Web/Mail-to-Phone", "Mail-to-Web/Mail-to-Phone", "Online Ad"), collapse = ", "),
    paste(c("App Panel", "IVR", "IVR/Live Phone/Text/Online Panel/Email", "IVR/Online Panel", "IVR/Online Panel/Email", "IVR/Online Panel/Text-to-Web", "IVR/Online Panel/Text-to-Web/Email", "IVR/Text", "IVR/Text-to-Web", "IVR/Text-to-Web/Email", "Live Phone/Email", "Live Phone/Online Panel/Mail-to-Web", "Live Phone/Text/Online Ad", "Live Phone/Text-to-Web/Email", "Live Phone/Text-to-Web/Email/Mail-to-Web", "Live Phone/Text-to-Web/Online Ad", "Online Panel/Email", "Online Panel/Email/Text-to-Web", "Online Panel/Online Ad", "Text-to-Web/Email", "Text-to-Web/Online Ad"), collapse = ", "),
    paste(c("IVR/Live Phone/Online Panel", "IVR/Live Phone/Online Panel/Text-to-Web", "IVR/Live Phone/Text", "IVR/Live Phone/Text-to-Web", "Live Phone/Online Panel/App Panel", "Live Phone/Online Panel/Text", "Live Phone/Online Panel/Text-to-Web", "Live Phone/Online Panel/Text-to-Web/Text", "Live Phone/Text", "Live Phone/Text/Online Panel", "Live Phone/Text-to-Web", "Live Phone/Text-to-Web/App Panel", "Online Panel", "Online Panel/Text", "Online Panel/Text-to-Web", "Online Panel/Text-to-Web/Text", "Text", "Text-to-Web"), collapse = ", "),
    paste(c("Live Phone", "Live Phone/Online Panel", "Live Phone/Probability Panel", "Online Panel/Probability Panel", "Probability Panel"), collapse = ", ")
  )
)

# Print the summary of methodologies and their levels using kable
kable(methodology_summary, col.names = c("Level", "Methodologies")) %>%
  column_spec(1, width = "1.5cm") %>% # Adjust the width of the first column
  column_spec(2, width = "13cm")
```
The different methodologies were evaluated based on reliability scores ranging from 1 to 10. The scores of 51 combinations were calculated by averaging the individual scores of each methodology in the combination. The results were classified into four levels: high reliability (8.5-10), medium-high reliability (7-8.49), medium reliability (5-6.99), and low reliability (below 5). Methodologies were scored based on several criteria, including statistical rigor, representativeness, response rate, interaction quality, and cost efficiency. High-scoring methodologies, such as those employing strict statistical sampling methods like Probability Panels or those using Live Phone surveys with broad coverage and low refusal rates, received high scores due to their strong representativeness and reliability. Medium-high scoring methodologies included Online Panels, which offer good coverage and low cost but are susceptible to self-selection bias, and Text-to-Web methods, which improve response rates but may have limited representativeness depending on the target demographics. Medium-scoring methodologies, such as App Panels and IVR (Interactive Voice Response), tend to lack broad representativeness or have limitations in interaction quality, making them suitable for niche audiences but not generalizable to a wider population. Low-scoring methodologies, including Email Surveys and methods relying on Online Ads, often suffer from low response rates and significant selection bias, which negatively impact their reliability. These scoring criteria ensure that the methodologies are evaluated in a consistent manner, with higher scores reflecting stronger statistical foundations, broader representativeness, and better data quality.

Additionally, the reason we only compared the data of Trump and Harris to predict which of them would win the election is that, after comparing the weighted competitiveness scores of all candidates, we found that the top three — Trump, Harris, and Biden — had significantly higher scores than the others. As shown in @tbl-t5c, the third-place candidate, Harris, had a weighted competitiveness score of 180714535, which is 5.15 times higher than the fourth-place score of 34987031. Considering that Biden has withdrawn from the race, we ultimately decided to only predict between the most competitive candidates, Trump and Harris. The specific weighting formula is as follows:

\begin{align}
& weighted\_score  = \frac{ {\textstyle \sum_{i  = 1}^{n}score_i} }{n}\times {\textstyle \sum_{i  = 1}^{n}Sample\_Size_i} \\
& \text{Where: }\notag\\
&\hspace{1cm}n\text{ represents the number of polls nominating this candidate.}\notag\\
&\hspace{1cm}Score_i\text{ represents the score obtained by the candidate in the } i^{th}\text{ poll.}\notag\\
&\hspace{1cm}Sample\_Size_i\text{ represents the sample size of the } i^{th}\text{ poll.}\notag
\end{align}

```{r}
# Define the directory path containing the parquet files
p <- "data/03-cleaned_data"
parquet_files <- list.files(path = here::here(p), full.names = TRUE)

# Initialize an empty dataframe to store the weighted score for each file
weighted_scores <- data.frame(Candidate = character(), Weighted_Score = numeric(), stringsAsFactors = FALSE)

# Iterate over each parquet file
for (file in parquet_files) {
  # Read the parquet file
  df <- read_parquet(here::here(file))
  
  # Calculate the mean of score and sample_size
  score_mean <- mean(df$score, na.rm = TRUE)
  sample_size_mean <- mean(df$sample_size, na.rm = TRUE)
  
  # Calculate the weighted score (multiply by total number of rows)
  weighted_score <- score_mean * sample_size_mean * nrow(df)
  
  # Append the result to the weighted_scores dataframe
  weighted_scores <- rbind(weighted_scores, data.frame(Candidate = sub('_cleaned_data.parquet$', '', basename(file)), Weighted_Score = weighted_score))
}

# Get the top 5 weighted scores
top_5_weighted_scores <- weighted_scores %>% 
  arrange(desc(Weighted_Score)) %>% 
  head(5)

# Print the top 5 weighted scores using kable
top_5_weighted_scores %>% kable()

```


```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-t5c
#| tbl-cap: "Top 5 Candidates"
# Find the top 5 candidates.
candidate_ranking <- raw_data %>%
  group_by(candidate_name) %>%
  summarize(
    poll_count = n(),                    
    avg_weighted_pct = mean(poll_count * pct, na.rm = TRUE)  
  ) %>%
  arrange(desc(avg_weighted_pct)) %>%    
  slice_head(n = 5)                       
kable(candidate_ranking, col.names = c("candidate", "number of polls", "weighted score"))
  
```









## Model set-up
### response variable
在此章节中，我们用到的数据都是哈里斯和特朗普的训练集。
score是我们模型的response variable，它代表的是某个候选人在某次选票中胜利的可能性，越大代表着该候选人竞选成功的概率越大，通常情况下与该候选人在那次选票中的支持率一样。
下图可以看出来哈里斯和特朗普的score都接近于正态分布。其中川普的score呈现一个对称的趋势，其中最多的score是在50左右。训练集中，川普的score平均数是44.63，方差是24.68。相比之下，哈里斯的score分布有一些偏向于左侧的倾斜。训练集中，哈里斯的score平均数高于特朗普为46.92，方差略低于川普为20.96。值得注意的是川普数据的样本量为3960，而哈里斯只有1636.

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate mean, variance, and sample size
summary_stats <- bind_rows(
  train_Trump %>% summarise(mean = round(mean(score, na.rm = TRUE), 2), variance = round(var(score, na.rm = TRUE), 2), sample_size = n()) %>% mutate(dataset = "train_Trump"),
  train_Harris %>% summarise(mean = round(mean(score, na.rm = TRUE), 2), variance = round(var(score, na.rm = TRUE), 2), sample_size = n()) %>% mutate(dataset = "train_Harris")
)

# Display results using kable
summary_stats %>%
  select(dataset, mean, variance, sample_size) %>%
  kable()

```

```{r}
#| warning: false
#| message: false
#| echo: false
# Plot a histogram for the 'pct' variable
ggplot(train_Trump, aes(x = score)) +
  geom_histogram(binwidth = 2, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of pct", x = "pct", y = "Frequency")
ggplot(train_Harris, aes(x = score)) +
  geom_histogram(binwidth = 2, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of pct", x = "pct", y = "Frequency")
```


### Predictor
我们的predictors包含以下变量：
```{r}
#| warning: false
#| message: false
#| echo: false
predictors <- c("pollscore","methodology","transparency_score","sample_size","population", 
           "ranked_choice_reallocated", "hypothetical", "duration")
predictors
```

下图展示了在川普的训练集中，numerical predictor 之间的关系。没有明显的趋势代表着它们之间没有明显的correlation。
```{r, fig.width=10, fig.height=10}
#| warning: false
#| message: false
#| echo: false
data2 = train_Trump %>% select("pollscore","transparency_score","sample_size","duration")
pairs( data2 , main = "Predictor vs predictor")
```

关于categorical的：。。。。。。。。。。。。。。。。



### alternative models
最开始我们的模型是

```{r}
#| warning: false
#| message: false
#| echo: false
Trump_model_0 <- lm(
  score ~ numeric_grade + pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Trump)
Harris_model_0 <- lm(
  score ~ numeric_grade + pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Harris)
```

因为我们考虑到numeric_grade和pollscore之间有强线性相关，我们舍弃了这一方案。
```{r}
#| warning: false
#| message: false
#| echo: false
# Plot relationship between numeric_grade and pollscore for train_Trump
ggplot(train_Trump, aes(x = numeric_grade, y = pollscore)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Relationship between Numeric Grade and Pollscore (train_Trump)",
       x = "Numeric Grade",
       y = "Pollscore")

# Plot relationship between numeric_grade and pollscore for train_Harris
ggplot(train_Harris, aes(x = numeric_grade, y = pollscore)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Relationship between Numeric Grade and Pollscore (train_Harris)",
       x = "Numeric Grade",
       y = "Pollscore")
```



这个是我们的第二个方案。虽然predictors之间没有了相关性，但是methodology，ranked_choice_reallocated，这两个变量并不statistical significant，因为他们的p value都大于0.05.

```{r}
#| warning: false
#| message: false
#| echo: false
Trump_model_1 <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Trump)
Harris_model_1 <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Harris)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Get the summary of the model
Harris_summary <- summary(Harris_model_1)
# Extract coefficients from the summary
coefficients <- Harris_summary$coefficients
# Extract p-values
Harris_p_values <- coefficients[, 4]
# Create a data frame with the results
Harris_results_table <- data.frame(
  Variable = rownames(coefficients),
  P_Value = format(Harris_p_values, scientific = TRUE)
)
Harris_kable <- kable(Harris_results_table[, 2, drop = FALSE], caption = "Harris", col.names = c("Variable", "P-value"))
# Get the summary of the model
Trump_summary <- summary(Trump_model_1)
# Extract coefficients from the summary
coefficients <- Trump_summary$coefficients
# Extract p-values
Trump_p_values <- coefficients[, 4]
# Create a data frame with the results
Trump_results_table <- data.frame(
  Variable = rownames(coefficients),
  P_Value = format(Trump_p_values, scientific = TRUE)
)
Trump_kable <- kable(Trump_results_table[, 2, drop = FALSE], caption = "Trump", col.names = c("Variable", "P-value"))

grid.arrange(tableGrob(Trump_kable), tableGrob(Harris_kable), nrow = 1)


```

因此，我们有有了最后的模型。
```{r}
#| warning: false
#| message: false
#| echo: false
"
Trump_model <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical, data = train_Trump)
Harris_model <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical, data = train_Harris)
"
summary(Trump_model)
summary(Harris_model)
```



## validation
从您的结果来看，所有变量的 GVIF 值都在 1 到 1.3 之间，这些数值非常低，表明各个自变量之间的共线性很小，模型并没有因为共线性而受到显著影响。
```{r}
#| warning: false
#| message: false
#| echo: false
vif(Trump_model)
vif(Harris_model)
```

```{r}
#| warning: false
#| message: false
#| echo: false
par(mfrow=c(2,2))
plot(Harris_model,1)
plot(Harris_model,2)
```

```{r}

par(mfrow=c(2,2))
plot(Trump_model,1)
plot(Trump_model,2)
```
然后就是描述一下response variable是normal的，然后numerical variable没有显著关系（这些在打他部分有讲过）
总结，满足了MLR的条件，说明我们的好
```{r,message=FALSE, echo=FALSE,warning=FALSE,fig.height = 10, fig.width=10}
# Generate predictions using the model
plots <- list()
predictions <- predict(Harris_model, newdata = test_Harris)

actual <- test_Harris$score

results_df <- data.frame(Actual = actual, Predicted = predictions)

# Plot the predicted values vs actual values
plots[["Harris"]]<-ggplot(results_df, aes(x = predictions, y = actual)) +
  geom_point(color = "blue") + # Scatter plot of predicted vs actual values
  labs(x = "Predicted Values", y = "Actual Values", title = "Comparison of Predicted and Actual Values") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") + # Add reference line y = x
  theme_minimal() # Use minimal theme for the plot


# Generate predictions using the model
predictions_1 <- predict(Trump_model, newdata = test_Trump)

actual_1 <- test_Trump$score

results_df_1 <- data.frame(Actual = actual_1, Predicted = predictions_1)

# Plot the predicted values vs actual values
plots[["Trump"]] <-ggplot(results_df_1, aes(x = predictions_1, y = actual_1)) +
  geom_point(color = "blue") + # Scatter plot of predicted vs actual values
  labs(x = "Predicted Values", y = "Actual Values", title = "Comparison of Predicted and Actual Values") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") + # Add reference line y = x
  theme_minimal() # Use minimal theme for the plot

### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 1, nrow = 2, heights = unit(rep(4, 8), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)


```

# Result
## featured values used in prediction

In our analysis, we designated specific poll-related features as "featured values" to serve as representative indicators within each candidate's dataset. These featured values were chosen to highlight the most impactful aspects of the polling data that consistently influenced the support scores for Donald Trump and Kamala Harris. By selecting these representative values, we aimed to streamline the analysis and focus on the factors that most strongly characterized each candidate’s data.

We selected representative feature values for each candidate's dataset by processing each variable based on its type. For numeric variables (e.g., numeric_grade, pollscore, transparency_score, duration, sample_size), we determined whether to use the mean or median by evaluating skewness; variables with low skewness used the mean, while more skewed variables used the median to represent typical values. Categorical variables (e.g., methodology, population) were represented by the most frequent category, while Boolean variables (e.g., ranked_choice_reallocated, hypothetical) were set to TRUE or FALSE based on the most common value. This approach allowed us to capture the key characteristics of each candidate's data in a summarized form.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
select_feature_value <- function(data, candidate_name) {
  feature_values <- list()
  for (col_name in names(data)) {
    col_data <- data[[col_name]]
    # Numeric variables: Choose mean or median based on skewness
    if (is.numeric(col_data)) {
      # Check if there are enough valid values to compute skewness
      if (sum(!is.na(col_data)) > 1) {  # Ensure there is more than one valid value
        skew_val <- skewness(col_data, na.rm = TRUE)
        if (!is.na(skew_val) && skew_val < 1) {
          feature_values[[col_name]] <- mean(col_data, na.rm = TRUE)
        } else {
          feature_values[[col_name]] <- median(col_data, na.rm = TRUE)
        }
      } else {
        # Default to median if skewness cannot be computed
        feature_values[[col_name]] <- median(col_data, na.rm = TRUE)
      }
    }
    
    # Categorical variables: Choose mode (most frequent value)
    else if (is.character(col_data)) {
      feature_values[[col_name]] <- Mode(col_data)
    }
    
    # Boolean variables: Choose TRUE or FALSE based on which one appears more frequently
    else if (is.logical(col_data)) {
      true_count <- sum(col_data, na.rm = TRUE)
      false_count <- sum(!col_data, na.rm = TRUE)
      feature_values[[col_name]] <- if (true_count >= false_count) TRUE else FALSE
    }
  }
  # Add the candidate name to the results
  feature_values[["Candidate"]] <- candidate_name
  return(feature_values)
}

# Define a function to calculate the mode (most frequent value)
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Calculate feature values for each candidate
trump_features <- select_feature_value(full_Trump, "Donald Trump")
harris_features <- select_feature_value(full_Harris, "Kamala Harris")

# Round numeric columns to two decimal places before pivoting
all_candidate_features <- all_candidate_features %>%
  mutate(across(everything(), as.character))  # Convert all columns to character for compatibility in pivot_longer

# Pivot the data to create a vertically aligned table with candidate names in the first row
all_candidate_features_long <- all_candidate_features %>%
  pivot_longer(cols = -Candidate, names_to = "Variable", values_to = "Value") %>%
  pivot_wider(names_from = Candidate, values_from = Value)

# Display the final table with kable
kable(all_candidate_features_long, caption = "Featured Values for Each Candidate")


```
## Prediction result of the linear model

Using the selected feature values for each candidate, we applied our trained predictive models to estimate the support levels for Kamala Harris and Donald Trump. The bar plot above illustrates the predicted values derived from our analysis. According to the model, Kamala Harris has a predicted support value of approximately 47.65, while Donald Trump is predicted to receive a support value of around 43.51. These predictions suggest an advantage for Kamala Harris over Donald Trump in terms of expected support within the context of the data used.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Store predictions in a data frame
predictions <- data.frame(
  Candidate = c("Kamala Harris", "Donald Trump"),
  Prediction = c(Harris_predict, Trump_predict)
)

# Create the bar plot
ggplot(predictions, aes(x = Candidate, y = Prediction, fill = Candidate)) +
  geom_bar(stat = "identity", width = 0.5) +
  labs(title = "Predicted Values for Each Candidate",
       x = "Candidate",
       y = "Prediction") +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_text(aes(label = Prediction), vjust = -0.3)
```
## Conclusion

Overall, our approach demonstrates how feature engineering and predictive modeling can offer insights into candidate support based on the available data. However, it is important to interpret these results cautiously, as they rely on specific variables and assumptions embedded within the dataset. In this analysis, we aggregated representative feature values for each candidate by using the mean or median for numeric variables, the mode for categorical variables, and the most frequent occurrence for Boolean values. Further refinement and additional data could enhance the robustness of these predictions, contributing to a more comprehensive forecast in future studies.

# Discussion




