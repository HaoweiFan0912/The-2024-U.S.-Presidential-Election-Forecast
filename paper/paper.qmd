---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---
```{r}
#| include: false
#| warning: false
#| message: false
#| echo: false
#### Workspace setup ####
library(tidyverse)
library(knitr)
library(dplyr)
library(arrow)
library(patchwork)
library(car)
library(kableExtra)
library(gridExtra)
library(moments)
set.seed(912)
#### Read data ####
raw_data <- read_csv(here::here("data/01-raw_data/raw_data.csv"))
train_Trump <- read_parquet(here::here("data/02-analysis_data/01-training/train_Trump.parquet"))
train_Harris <- read_parquet(here::here("data/02-analysis_data/01-training/train_Harris.parquet"))
test_Trump <- read_parquet(here::here("data/02-analysis_data/02-testing/test_Trump.parquet"))
test_Harris <- read_parquet(here::here("data/02-analysis_data/02-testing/test_Harris.parquet"))
full_Trump <- read_parquet(here::here("data/02-analysis_data/00-full/full_Trump.parquet"))
full_Harris <- read_parquet(here::here("data/02-analysis_data/00-full/full_Harris.parquet"))
Trump_model <- readRDS(here::here("models/Trump_model.rds"))
Harris_model <- readRDS(here::here("models/Harris_model.rds"))
```

# Introduction

# Data {#sec-data}

## Overview

## Raw data
Raw data 一共包含了52个variable以及17133个sample.
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-vord
#| tbl-cap: "Varibales of raw data"

# Get the column names and arrange them into multiple columns
column_names <- names(raw_data)
num_columns <- 3  # Set the desired number of columns
num_rows <- ceiling(length(column_names) / num_columns)
matrix_data <- matrix(c(column_names, rep("", num_columns * num_rows - length(column_names))), 
                      nrow = num_rows, byrow = TRUE)

# Convert the matrix to a data frame and format it with kable, set font size, and adjust header styling to remove extra row
kable(as.data.frame(matrix_data), 
      col.names = NULL)
```
其中重要的variables，其余的在appdendix
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-ivatd
#| tbl-cap: "Important variables and their descriptions"

variable_descriptions <- data.frame(
  Variable = c("poll_id", "methodology", "population", "ranked_choice_reallocated",
               "hypothetical", "answer", "numeric_grade", "pollscore", 
               "transparency_score", "start_date", "end_date", "sample_size", "pct"),
  Description = c(
    "Unique identifier for each poll conducted.",
    "The method used to conduct the poll (e.g., Online Panel).",
    "The abbreviated description of the respondent group, typically indicating their voting status (e.g., 'lv' for likely voters).",
    "Indicates if ranked-choice voting reallocations have been applied in the results.",
    "Indicates whether the poll is about a hypothetical match-up.",
    "The response or answer choice given in the poll (e.g., the candidate's party).",
    "A numeric rating given to the pollster to indicate their quality or reliability (e.g., 3.0).",
    "A numeric value representing the score or reliability of the pollster in question (e.g., -1.1).",
    "A score reflecting the pollster's transparency about their methodology (e.g., 9.0).",
    "The date the poll began (e.g., 10/8/24).",
    "The date the poll ended (e.g., 10/11/24).",
    "The total number of respondents participating in the poll (e.g., 2712).",
    "The percentage of the vote or support that the candidate received in the poll (e.g., 51.0 for Kamala Harris)."
  )
)

# Create the table using kable
kable(variable_descriptions) %>%
  kable_styling() %>%
  column_spec(1, width = "4.5cm") %>% # Adjust the width of the first column
  column_spec(2, width = "10cm")    # Adjust the width of the second column
```
52个varibles中以下几个与我们的project明显无关，我们在此不做讨论：
"notes", "url", "url_article", "url_topline", "url_crosstab", "source"
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
del_1 <- c("notes", "url", "url_article", "url_topline", "url_crosstab", "source")
droped_data <- raw_data %>% select(-any_of(del_1))
```
此外，还有一些相同的variables，我们保留其一，剩下的也不做讨论，它们包括："pollster", "sponsors", "display_name", "pollster_rating_name", "sponsor_candidate", "endorsed_candidate_name", "population_full", "candidate_id", "candidate_name"
```{r}
#| warning: false
#| message: false
#| echo: false
# 这里需要画一个table，展示删除的重复变量
del_2 <- c("pollster", "sponsors", "display_name", "pollster_rating_name", "sponsor_candidate", "endorsed_candidate_name",
           "population_full", "candidate_id", "candidate_name")
droped_data <- droped_data %>% select(-any_of(del_2))
```
常数变量我们也不做讨论，因为无法影响我们的预测，它们是：
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-cv
#| tbl-cap: "Constant variables"
# Identify variables where all values are the same (including NA)
same_value_variables <- names(droped_data)[sapply(droped_data, function(x) length(unique(x)) == 1)]
# Create a data frame with variables and their unique values
same_value_data <- data.frame(Variable = same_value_variables, Value = sapply(same_value_variables, function(var)
unique(na.omit(droped_data[[var]]))[1]))
# Print the names of variables with all identical values using kable
kable(same_value_data[, 2, drop = FALSE], col.names = c("Variable", "Value"))
del_4 <- c("endorsed_candidate_id", "endorsed_candidate_party", "subpopulation", "cycle", "election_date", "stage", "nationwide_batch", 
           "office_type", "seat_number", "seat_name")
droped_data <- droped_data %>% select(-any_of(del_4))
```
其中categorical的有"poll_id", "pollster_id", "sponsor_ids", "pollster_rating_id", "methodology", "state",
         "sponsor_candidate_id", "sponsor_candidate_party", "question_id", "population", "tracking", "created_at", "internal",
         "partisan","race_id", "ranked_choice_reallocated", "ranked_choice_round", "hypothetical","party","answer"
```{r}
#| warning: false
#| message: false
#| echo: false
catego <- c("poll_id", "pollster_id", "sponsor_ids", "pollster_rating_id", "methodology", "state",
         "sponsor_candidate_id", "sponsor_candidate_party", "question_id", "population", "tracking", "created_at", "internal",
         "partisan","race_id", "ranked_choice_reallocated", "ranked_choice_round", "hypothetical","party","answer")
```
重要的categorical为下面的，剩下的将在appendix阐述："poll_id", "methodology", "population", "ranked_choice_reallocated", "hypothetical","answer"
```{r}
#| warning: false
#| message: false
#| echo: false
catego_inp <- c("poll_id", "methodology", "population", "ranked_choice_reallocated", "hypothetical","answer")
```
一共有3530个poll
```{r}
#| warning: false
#| message: false
#| echo: false
# Get unique Poll IDs and print the count
unique_poll_ids <- unique(raw_data$poll_id)
```
描述
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: fig-bv
#| fig-cap: "Boolean variables"
plots <- list()
# Create bar charts for 'ranked_choice_reallocated' and 'hypothetical'
plots[["ranked_choice"]] <- ggplot(raw_data, aes(x = ranked_choice_reallocated)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Ranked Choice Reallocated", x = "Ranked Choice Reallocated", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )

plots[["hypothetical"]] <- ggplot(raw_data, aes(x = hypothetical)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Hypothetical", x = "Hypothetical", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )

# Combine and print the plots using patchwork
combined_plot <- wrap_plots(plots, ncol = 2, nrow = 1, heights = unit(rep(3, 4), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)

```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-cv
#| fig-cap: "Catogorical variables"

plots <- list()
# Find the top 3 most frequent values in 'methodology' and group others as 'Other'
methodology_counts <- sort(table(raw_data$methodology), decreasing = TRUE)
top_3_methodologies <- names(methodology_counts)[1:3]
raw_data$methodology_grouped <- ifelse(raw_data$methodology %in% top_3_methodologies, raw_data$methodology, "Other")
# Create a bar chart for the grouped 'methodology'
plots[["methodology"]] <- ggplot(raw_data, aes(x = methodology_grouped)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Top 3 Methodologies and Others", x = "Methodology", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )
plots[["population"]] <- ggplot(raw_data, aes(x = population)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Population", x = "Population", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )
# Find the top 3 most frequent values in 'answer' and group others as 'Other'
answer_counts <- sort(table(raw_data$answer), decreasing = TRUE)
top_3_answer <- names(answer_counts)[1:3]
raw_data$answer <- ifelse(raw_data$answer %in% top_3_answer, raw_data$answer, "Other")
# Create a bar chart for the grouped 'answer'
plots[["answer"]] <- ggplot(raw_data, aes(x = answer)) +
  geom_bar(fill = "#69b3a2", color = "black", alpha = 0.8) +
  labs(title = "Top 3 answer and Others", x = "answer", y = "Count") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),
    axis.text = element_text(size = 10)
  )
combined_plot <- wrap_plots(plots, ncol = 3, nrow = 1, heights = unit(rep(8, 4), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)
```
以及numerical的variables："numeric_grade"      "pollscore"          "transparency_score" "start_date"         "end_date"        "sample_size" "pct"
```{r}
#| warning: false
#| message: false
#| echo: false
numer <- droped_data %>% select(-any_of(catego))
```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-donvp1
#| fig-cap: "Distribution of numerical varibales part 1"
### Create Plots for Numeric Variables ###
# Create a list to store plots
plots <- list()
# Loop through selected numeric variables and plot their distributions
for (variable in names(numer %>% select(numeric_grade, pollscore, transparency_score))) {
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(binwidth = 0.5, fill = "#69b3a2", color = "black", alpha = 0.8) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
    theme_minimal(base_size = 30) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 10),
      axis.text = element_text(size = 10)
    )
}
### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 3, nrow = 1, heights = unit(rep(8, 4), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)
```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-donvp2
#| fig-cap: "Distribution of numerical varibales part 2"
### Create Plots for Numeric Variables ###
# Create a list to store plots
plots <- list()
# Loop through selected numeric variables and plot their distributions
for (variable in names(numer %>% select(sample_size, pct))) {
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(binwidth = 5, fill = "#69b3a2", color = "black", alpha = 0.8) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
    theme_minimal(base_size = 30) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 10),
      axis.text = element_text(size = 10)
    )
}
### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 2, nrow = 1, heights = unit(rep(8, 8), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)
```
描述
```{r, fig.pos="H", fig.width=18, fig.height=18}
#| warning: false
#| message: false
#| echo: false
#| label: fig-dodv
#| fig-cap: "Distribution of date varibales"

### Define Variables and Prepare Data ###
# Convert start_date and end_date to Date type
raw_data$start_date <- ymd(raw_data$start_date)
raw_data$end_date <- ymd(raw_data$end_date)
# Define the date variables to plot
date_variables <- c("start_date", "end_date")
### Create Plots for Date Variables ###
# Loop through selected date variables and plot their distributions
plots <- list()
for (variable in names(numer %>% select(start_date, end_date))) {
  plots[[variable]] <- ggplot(raw_data, aes_string(x = variable)) +
    geom_histogram(binwidth = 80, fill = "#69b3a2", color = "black", alpha = 0.8) +
    labs(title = paste("Distribution of", variable), x = variable, y = "Frequency") +
        theme_minimal(base_size = 30) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      axis.title = element_text(size = 10),
      axis.text = element_text(size = 10)
    )
}
### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 2, nrow = 1, heights = unit(rep(8, 4), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)

```
## Cleaned data
In the raw data, we initially identified a total of 52 variables. Some of these variables, such as 'url', are clearly unrelated to the objectives of this project. There are also constant variables, such as 'election_date', which consistently contains the value '11/5/24'. Additionally, we found duplicate variables conveying the same information, like 'pollster_id' and 'pollster'. Therefore, we first removed these irrelevant and redundant variables. The remaining variables are as follows:
```{r, fig.height=90, fig.width=90}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-rv
#| tbl-cap: "Remained variables"

# Get the column names and arrange them into multiple columns
column_names <- names(droped_data)
num_columns <- 3  # Set the desired number of columns
num_rows <- ceiling(length(column_names) / num_columns)
matrix_data <- matrix(c(column_names, rep("", num_columns * num_rows - length(column_names))), 
                      nrow = num_rows, byrow = TRUE)

# Convert the matrix to a data frame and format it with kable, set font size, and adjust header styling to remove extra row
kable(as.data.frame(matrix_data), 
      col.names = NULL)
```
Next, we calculated the percentage of missing values for each variable across the entire dataset. We then removed all variables with more than 40% missing values. These variables, along with their respective proportions of missing values, are as follows:
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-vwbpomv
#| tbl-cap: "Variables with big porpotion of missing values"
na_proportions <- sapply(names(droped_data), function(var) {
  round(mean(is.na(raw_data[[var]])), 2)
})

# Create a data frame with variable names and their NA proportions
na_proportions_data <- data.frame(Variable = names(droped_data), NA_Proportion = na_proportions)

# Filter variables with NA proportion greater than 40%
high_na_proportions <- na_proportions_data[na_proportions_data$NA_Proportion > 0.4, ]

# Print the NA proportions greater than 40% using kable
kable(high_na_proportions[, 2, drop = FALSE], col.names = c("Variable", "NA Proportion"))

del_5 <- c("sponsor_ids", "state", "sponsor_candidate_id", "sponsor_candidate_party", "tracking",
           "internal","partisan","ranked_choice_round")
droped_data <- droped_data %>% select(-any_of(del_5))

```
Since the influence of pollsters can be quantified using their ratings, such as 'numeric_grade', 'pollscore', and 'transparency_score', we removed these variables to simplify the dataset and the model. Similarly, 'created_at' was also removed due to its strong correlation with 'start_date'. 
```{r}
#| warning: false
#| message: false
#| echo: false
del_6 <- c("pollster_id", "pollster_rating_id", "created_at")
droped_data <- droped_data %>% select(-any_of(del_6))
```
Finally, due to the limitations of our model, we removed 'race_id', 'party', and 'question_id'. The reason for this is that we will extract and analyze the data for each candidate individually, which makes 'race_id' and 'party' constant within the corresponding dataset. Additionally, 'question_id' contains 6,421 unique values, making it unsuitable for categorization, and we removed it to avoid overfitting the model.
```{r}
#| warning: false
#| message: false
#| echo: false
# Get unique Question IDs and print the count
unique_question_ids <- unique(raw_data$question_id)
```
Finally, the remaining variables are as follows:
```{r, fig.height=30, fig.width=30}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-fv
#| tbl-cap: "Final variables"
final <- c("poll_id","numeric_grade","pollscore","methodology","transparency_score","sample_size","population", 
           "ranked_choice_reallocated", "hypothetical", "answer","pct","start_date", "end_date")

# Get the column names and arrange them into multiple columns
column_names <- final
num_columns <- 3  # Set the desired number of columns
num_rows <- ceiling(length(column_names) / num_columns)
matrix_data <- matrix(c(column_names, rep("", num_columns * num_rows - length(column_names))), 
                      nrow = num_rows, byrow = TRUE)

# Convert the matrix to a data frame and format it with kable, set font size, and adjust header styling to remove extra row
kable(as.data.frame(matrix_data), 
      col.names = NULL)
```
After finalizing the variables, we first created a new variable named 'duration', which replaced 'start_date' and 'end_date'. This new variable represents the number of days between 'start_date' and 'end_date'.Next, we categorized the 51 different methodologies into four levels, ranging from the least reliable and accurate (level_1) to the most reliable (level_4). 

Subsequently, we handled the missing values by imputing numerical variables with their mean values and categorical variables with their mode. Since our results are not exact percentages, we used 'score' to name what would typically be called 'pct'. We then finalize and tidy up the variable names.

Next, we extracted the data for each candidate individually. We calculated a weighted score by weighting according to the number of times each candidate was mentioned in the polls. After comparison, we observed that the top three candidates—Trump, Harris, and Biden—had significantly higher scores than the remaining candidates. Given that Biden has withdrawn from the race, we are now focusing only on the datasets for Trump and Harris for further analysis. The specific weighted scores for the top five candidates are as follows:
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-t5c
#| tbl-cap: "Top 5 Candidates"
# Find the top 5 candidates.
candidate_ranking <- raw_data %>%
  group_by(candidate_name) %>%
  summarize(
    poll_count = n(),                    
    avg_weighted_pct = mean(poll_count * pct, na.rm = TRUE)  
  ) %>%
  arrange(desc(avg_weighted_pct)) %>%    
  slice_head(n = 5)                       
kable(candidate_ranking, col.names = c("candidate", "number of polls", "weighted score"))
  
```
Next, we split the data for Trump and Harris into a training set (70%) and a test set (30%). These four datasets form our analysis data. Below is a portion of the Trump training set for reference:
```{r}
#| warning: false
#| message: false
#| echo: false
kable(head(train_Trump), col.names = names(train_Trump))
```
## Measurement

## Similar dataset

# Model

## Model overview
我们一共有2个model，分别用来预测川普和哈里斯在2024年11月5日美国总统竞选的最终支持率。

\begin{align} 
Score_{Trump} = &\beta_1Pollscore + \beta_2Transparency\_score + \beta_3Duration + \\
        &\beta_4Sample\_size + \beta_5Population + \beta_6Hypothetical + \beta_0 \notag \\[0.5cm]
Score_{Harris} = &\alpha_1Pollscore + \alpha_2Transparency\_score + \alpha_3Duration + \\
        &\alpha_4Sample\_size + \alpha_5Population + \alpha_6Hypothetical + \alpha_0 \notag
\end{align}

值得注意的是我们使用的是Multiple linear regression (MLR), 意味着我们的假设：
1. 多元线性回归的核心前提是因变量（结果变量）与自变量之间存在线性关系。可以通过散点图直观检查这种线性关系，理想情况下应显示出直线关系而非曲线关系。
2. 残差（观测值与预测值之间的差异）呈正态分布。可以通过观察Q-Q 图来评估这一假设。
3. 自变量之间的相关性不过高，即避免多重共线性。这可以通过方差膨胀因子（VIF）来检测。
4. 同方差性：误差项（残差）的方差应在自变量的所有水平上保持一致。残差与预测值的散点图不应显示出明显的模式。

此外，在我们的模型中，duration变量是原数据中“start_date” 和 “end_date” 的差值，这意味着我们的模型无法解释时间序列对结果带来的影响。但是考虑到这两者之间存在的线性关系，我们不得已将其简化，以满足使用MLR的假设。

另外，原数据中methodology有51种不同的总类。categorical variable 过多的种类会增加我们模型的复杂度，因此我们将其简化为了4个level。
其中level 1 代表该种methodology的可靠性最低，level 4 代表该种methodology的可靠性最高。具体的分类如下：
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-mc
#| tbl-cap: "Methodology classfication"

# Create a summary data frame for the methodologies and their levels
methodology_summary <- data.frame(
  Level = c("level 1", "level 2", "level 3", "level 4"),
  Methodologies = c(
    paste(c("Email", "Email/Online Ad", "Live Phone/Text-to-Web/Email/Mail-to-Web/Mail-to-Phone", "Mail-to-Web/Mail-to-Phone", "Online Ad"), collapse = ", "),
    paste(c("App Panel", "IVR", "IVR/Live Phone/Text/Online Panel/Email", "IVR/Online Panel", "IVR/Online Panel/Email", "IVR/Online Panel/Text-to-Web", "IVR/Online Panel/Text-to-Web/Email", "IVR/Text", "IVR/Text-to-Web", "IVR/Text-to-Web/Email", "Live Phone/Email", "Live Phone/Online Panel/Mail-to-Web", "Live Phone/Text/Online Ad", "Live Phone/Text-to-Web/Email", "Live Phone/Text-to-Web/Email/Mail-to-Web", "Live Phone/Text-to-Web/Online Ad", "Online Panel/Email", "Online Panel/Email/Text-to-Web", "Online Panel/Online Ad", "Text-to-Web/Email", "Text-to-Web/Online Ad"), collapse = ", "),
    paste(c("IVR/Live Phone/Online Panel", "IVR/Live Phone/Online Panel/Text-to-Web", "IVR/Live Phone/Text", "IVR/Live Phone/Text-to-Web", "Live Phone/Online Panel/App Panel", "Live Phone/Online Panel/Text", "Live Phone/Online Panel/Text-to-Web", "Live Phone/Online Panel/Text-to-Web/Text", "Live Phone/Text", "Live Phone/Text/Online Panel", "Live Phone/Text-to-Web", "Live Phone/Text-to-Web/App Panel", "Online Panel", "Online Panel/Text", "Online Panel/Text-to-Web", "Online Panel/Text-to-Web/Text", "Text", "Text-to-Web"), collapse = ", "),
    paste(c("Live Phone", "Live Phone/Online Panel", "Live Phone/Probability Panel", "Online Panel/Probability Panel", "Probability Panel"), collapse = ", ")
  )
)

# Print the summary of methodologies and their levels using kable
kable(methodology_summary, col.names = c("Level", "Methodologies")) %>%
  column_spec(1, width = "1.5cm") %>% # Adjust the width of the first column
  column_spec(2, width = "13cm")
```
这样分的原因是：。。。。。。。。。。。。。。。

此外，之所以我们只对川普和哈里斯的数据进行比较，预测他们之间谁会竞选成功。是因为我们通过比较所有候选人的加权竞争力得分后发现，前三名：川普，哈里斯，以及拜登与其余候选人差距非常大。@tbl-t5c可以看出其中第三名哈里斯的加权竞争力得分是109501.54是第四名的18822.81分的5.8倍之多。考虑到拜登以及推出参选，我们最后决定只对竞争力最大的川普和哈里斯进行预测。具体加权公式如下：




weighted\_score =  \frac{ {\textstyle \sum_{i=1}^{n}score_i} }{n}\times \frac{ {\textstyle \sum_{i=1}^{n}Sample\_Size_i} }{n}  




```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-t5c
#| tbl-cap: "Top 5 Candidates"
# Find the top 5 candidates.
candidate_ranking <- raw_data %>%
  group_by(candidate_name) %>%
  summarize(
    poll_count = n(),                    
    avg_weighted_pct = mean(poll_count * pct, na.rm = TRUE)  
  ) %>%
  arrange(desc(avg_weighted_pct)) %>%    
  slice_head(n = 5)                       
kable(candidate_ranking, col.names = c("candidate", "number of polls", "weighted score"))
  
```









## Model set-up
### response variable
在此章节中，我们用到的数据都是哈里斯和特朗普的训练集。
score是我们模型的response variable，它代表的是某个候选人在某次选票中胜利的可能性，越大代表着该候选人竞选成功的概率越大，通常情况下与该候选人在那次选票中的支持率一样。
下图可以看出来哈里斯和特朗普的score都接近于正态分布。其中川普的score呈现一个对称的趋势，其中最多的score是在50左右。训练集中，川普的score平均数是44.63，方差是24.68。相比之下，哈里斯的score分布有一些偏向于左侧的倾斜。训练集中，哈里斯的score平均数高于特朗普为46.92，方差略低于川普为20.96。值得注意的是川普数据的样本量为3960，而哈里斯只有1636.

```{r}
#| warning: false
#| message: false
#| echo: false
# Calculate mean, variance, and sample size
summary_stats <- bind_rows(
  train_Trump %>% summarise(mean = round(mean(score, na.rm = TRUE), 2), variance = round(var(score, na.rm = TRUE), 2), sample_size = n()) %>% mutate(dataset = "train_Trump"),
  train_Harris %>% summarise(mean = round(mean(score, na.rm = TRUE), 2), variance = round(var(score, na.rm = TRUE), 2), sample_size = n()) %>% mutate(dataset = "train_Harris")
)

# Display results using kable
summary_stats %>%
  select(dataset, mean, variance, sample_size) %>%
  kable()

```

```{r}
#| warning: false
#| message: false
#| echo: false
# Plot a histogram for the 'pct' variable
ggplot(train_Trump, aes(x = score)) +
  geom_histogram(binwidth = 2, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of pct", x = "pct", y = "Frequency")
ggplot(train_Harris, aes(x = score)) +
  geom_histogram(binwidth = 2, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of pct", x = "pct", y = "Frequency")
```


### Predictor
我们的predictors包含以下变量：
```{r}
#| warning: false
#| message: false
#| echo: false
predictors <- c("pollscore","methodology","transparency_score","sample_size","population", 
           "ranked_choice_reallocated", "hypothetical", "duration")
predictors
```

下图展示了在川普的训练集中，numerical predictor 之间的关系。没有明显的趋势代表着它们之间没有明显的correlation。
```{r, fig.width=10, fig.height=10}
#| warning: false
#| message: false
#| echo: false
data2 = train_Trump %>% select("pollscore","transparency_score","sample_size","duration")
pairs( data2 , main = "Predictor vs predictor")
```

关于categorical的：。。。。。。。。。。。。。。。。



### alternative models
最开始我们的模型是

```{r}
#| warning: false
#| message: false
#| echo: false
Trump_model_0 <- lm(
  score ~ numeric_grade + pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Trump)
Harris_model_0 <- lm(
  score ~ numeric_grade + pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Harris)
```

因为我们考虑到numeric_grade和pollscore之间有强线性相关，我们舍弃了这一方案。
```{r}
#| warning: false
#| message: false
#| echo: false
# Plot relationship between numeric_grade and pollscore for train_Trump
ggplot(train_Trump, aes(x = numeric_grade, y = pollscore)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Relationship between Numeric Grade and Pollscore (train_Trump)",
       x = "Numeric Grade",
       y = "Pollscore")

# Plot relationship between numeric_grade and pollscore for train_Harris
ggplot(train_Harris, aes(x = numeric_grade, y = pollscore)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Relationship between Numeric Grade and Pollscore (train_Harris)",
       x = "Numeric Grade",
       y = "Pollscore")
```



这个是我们的第二个方案。虽然predictors之间没有了相关性，但是methodology，ranked_choice_reallocated，这两个变量并不statistical significant，因为他们的p value都大于0.05.

```{r}
#| warning: false
#| message: false
#| echo: false
Trump_model_1 <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Trump)
Harris_model_1 <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical + ranked_choice_reallocated +
    methodology, data = train_Harris)
```

```{r}
#| warning: false
#| message: false
#| echo: false
# Get the summary of the model
Harris_summary <- summary(Harris_model_1)
# Extract coefficients from the summary
coefficients <- Harris_summary$coefficients
# Extract p-values
Harris_p_values <- coefficients[, 4]
# Create a data frame with the results
Harris_results_table <- data.frame(
  Variable = rownames(coefficients),
  P_Value = format(Harris_p_values, scientific = TRUE)
)
Harris_kable <- kable(Harris_results_table[, 2, drop = FALSE], caption = "Harris", col.names = c("Variable", "P-value"))
# Get the summary of the model
Trump_summary <- summary(Trump_model_1)
# Extract coefficients from the summary
coefficients <- Trump_summary$coefficients
# Extract p-values
Trump_p_values <- coefficients[, 4]
# Create a data frame with the results
Trump_results_table <- data.frame(
  Variable = rownames(coefficients),
  P_Value = format(Trump_p_values, scientific = TRUE)
)
Trump_kable <- kable(Trump_results_table[, 2, drop = FALSE], caption = "Trump", col.names = c("Variable", "P-value"))

grid.arrange(tableGrob(Trump_kable), tableGrob(Harris_kable), nrow = 1)


```

因此，我们有有了最后的模型。
```{r}
#| warning: false
#| message: false
#| echo: false
"
Trump_model <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical, data = train_Trump)
Harris_model <- lm(
  score ~ pollscore + transparency_score + duration + sample_size + population + hypothetical, data = train_Harris)
"
summary(Trump_model)
summary(Harris_model)
```



## validation
从您的结果来看，所有变量的 GVIF 值都在 1 到 1.3 之间，这些数值非常低，表明各个自变量之间的共线性很小，模型并没有因为共线性而受到显著影响。
```{r}
#| warning: false
#| message: false
#| echo: false
vif(Trump_model)
vif(Harris_model)
```

```{r}
#| warning: false
#| message: false
#| echo: false
par(mfrow=c(2,2))
plot(Harris_model,1)
plot(Harris_model,2)
```

```{r}

par(mfrow=c(2,2))
plot(Trump_model,1)
plot(Trump_model,2)
```
然后就是描述一下response variable是normal的，然后numerical variable没有显著关系（这些在打他部分有讲过）
总结，满足了MLR的条件，说明我们的好
```{r,message=FALSE, echo=FALSE,warning=FALSE,fig.height = 10, fig.width=10}
# Generate predictions using the model
plots <- list()
predictions <- predict(Harris_model, newdata = test_Harris)

actual <- test_Harris$score

results_df <- data.frame(Actual = actual, Predicted = predictions)

# Plot the predicted values vs actual values
plots[["Harris"]]<-ggplot(results_df, aes(x = predictions, y = actual)) +
  geom_point(color = "blue") + # Scatter plot of predicted vs actual values
  labs(x = "Predicted Values", y = "Actual Values", title = "Comparison of Predicted and Actual Values") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") + # Add reference line y = x
  theme_minimal() # Use minimal theme for the plot


# Generate predictions using the model
predictions_1 <- predict(Trump_model, newdata = test_Trump)

actual_1 <- test_Trump$score

results_df_1 <- data.frame(Actual = actual_1, Predicted = predictions_1)

# Plot the predicted values vs actual values
plots[["Trump"]] <-ggplot(results_df_1, aes(x = predictions_1, y = actual_1)) +
  geom_point(color = "blue") + # Scatter plot of predicted vs actual values
  labs(x = "Predicted Values", y = "Actual Values", title = "Comparison of Predicted and Actual Values") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") + # Add reference line y = x
  theme_minimal() # Use minimal theme for the plot

### Combine and Print Plots ###
# Combine all individual plots into one using patchwork with 2 columns and 4 rows
combined_plot <- wrap_plots(plots, ncol = 1, nrow = 2, heights = unit(rep(4, 8), "in")) +
  plot_annotation(
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 14)
    )
  )
# Print the combined plot
print(combined_plot)


```

# Result
```{r, echo=FALSE, message=FALSE, warning=FALSE}
#select significant values based on variable type of each candidate

# Define the function to select feature values based on variable type
select_feature_value <- function(data, candidate_name) {
  feature_values <- list()
  for (col_name in names(data)) {
    col_data <- data[[col_name]]
    # Numeric variables: Choose mean or median based on skewness
    if (is.numeric(col_data)) {
      # Check if there are enough valid values to compute skewness
      if (sum(!is.na(col_data)) > 1) {  # Ensure there is more than one valid value
        skew_val <- skewness(col_data, na.rm = TRUE)
        if (!is.na(skew_val) && skew_val < 1) {
          feature_values[[col_name]] <- mean(col_data, na.rm = TRUE)
        } else {
          feature_values[[col_name]] <- median(col_data, na.rm = TRUE)
        }
      } else {
        # Default to median if skewness cannot be computed
        feature_values[[col_name]] <- median(col_data, na.rm = TRUE)
      }
    }
    
    # Categorical variables: Choose mode (most frequent value)
    else if (is.character(col_data)) {
      feature_values[[col_name]] <- Mode(col_data)
    }
    
    # Boolean variables: Choose TRUE or FALSE based on which one appears more frequently
    else if (is.logical(col_data)) {
      true_count <- sum(col_data, na.rm = TRUE)
      false_count <- sum(!col_data, na.rm = TRUE)
      feature_values[[col_name]] <- if (true_count >= false_count) TRUE else FALSE
    }
  }
  # Add the candidate name to the results
  feature_values[["Candidate"]] <- candidate_name
  return(feature_values)
}

# Define a function to calculate the mode (most frequent value)
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Calculate feature values for each candidate
trump_features <- select_feature_value(full_Trump, "Donald Trump")
harris_features <- select_feature_value(full_Harris, "Kamala Harris")

# Combine results into a single data frame for easy viewing
all_candidate_features <- bind_rows(trump_features, harris_features)

# Display the final table of feature values
print(all_candidate_features)

```

```{r}
Harris_predict<- round(predict(Harris_model, newdata = harris_features),2)
Trump_predict <- round(predict(Trump_model, newdata = trump_features),2)
Harris_predict
Trump_predict
```

# Discussion







